

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>使用Pyro进行推断： 从随机函数到边缘分布 &mdash; Pyro实例与教程 0.1.0 文档</title>
  

  
  
  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  

  

  
        <link rel="index" title="索引"
              href="genindex.html"/>
        <link rel="search" title="搜索" href="search.html"/>
    <link rel="top" title="Pyro实例与教程 0.1.0 文档" href="index.html"/>
        <link rel="next" title="SVI Part I: An Introduction to Stochastic Variational Inference in Pyro" href="svi_part_i.html"/>
        <link rel="prev" title="Pyro里的模型：从原分布到随机函数" href="intro_part_i.html"/> 

  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="index.html" class="icon icon-home"> Pyro实例与教程
          

          
          </a>

          
            
            
              <div class="version">
                0.1.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="在文档中搜索" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="intro_part_i.html">Pyro里的模型：从原分布到随机函数</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">使用Pyro进行推断： 从随机函数到边缘分布</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#一个简单的案例">一个简单的案例</a></li>
<li class="toctree-l2"><a class="reference internal" href="#如何表示边缘分布">如何表示边缘分布</a></li>
<li class="toctree-l2"><a class="reference internal" href="#基于数据的条件模型">基于数据的条件模型</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Flexible-Approximate-Inference-With-Guide-Functions">Flexible Approximate Inference With Guide Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Parametrized-Stochastic-Functions-and-Variational-Inference">Parametrized Stochastic Functions and Variational Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="#下一步">下一步</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="svi_part_i.html">SVI Part I: An Introduction to Stochastic Variational Inference in Pyro</a></li>
<li class="toctree-l1"><a class="reference internal" href="svi_part_ii.html">SVI Part II: Conditional Independence, Subsampling, and Amortization</a></li>
<li class="toctree-l1"><a class="reference internal" href="svi_part_iii.html">SVI Part III: ELBO Gradient Estimators</a></li>
<li class="toctree-l1"><a class="reference internal" href="vae.html">Variational Autoencoders</a></li>
<li class="toctree-l1"><a class="reference internal" href="bayesian_regression.html">Bayesian Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="dmm.html">Deep Markov Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="air.html">Attend Infer Repeat</a></li>
<li class="toctree-l1"><a class="reference internal" href="ss-vae.html">The Semi-Supervised VAE</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Pyro实例与教程</a>
        
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">索引</a> &raquo;</li>
        
      <li>使用Pyro进行推断： 从随机函数到边缘分布</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/intro_part_ii.ipynb.txt" rel="nofollow"> 源码</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput,
div.nbinput div.prompt,
div.nbinput div.input_area,
div.nbinput div[class*=highlight],
div.nbinput div[class*=highlight] pre,
div.nboutput,
div.nbinput div.prompt,
div.nbinput div.output_area,
div.nboutput div[class*=highlight],
div.nboutput div[class*=highlight] pre {
    background: none;
    border: none;
    padding: 0 0;
    margin: 0;
    box-shadow: none;
}

/* avoid gaps between output lines */
div.nboutput div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput,
div.nboutput {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput,
    div.nboutput {
        flex-direction: column;
    }
}

/* input container */
div.nbinput {
    padding-top: 5px;
}

/* last container */
div.nblast {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput div.prompt pre {
    color: #303F9F;
}

/* output prompt */
div.nboutput div.prompt pre {
    color: #D84315;
}

/* all prompts */
div.nbinput div.prompt,
div.nboutput div.prompt {
    min-width: 8ex;
    padding-top: 0.4em;
    padding-right: 0.4em;
    text-align: right;
    flex: 0;
}
@media (max-width: 540px) {
    div.nbinput div.prompt,
    div.nboutput div.prompt {
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput div.prompt.empty {
        padding: 0;
    }
}

/* disable scrollbars on prompts */
div.nbinput div.prompt pre,
div.nboutput div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput div.input_area,
div.nboutput div.output_area {
    padding: 0.4em;
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput div.input_area,
    div.nboutput div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput div.input_area {
    border: 1px solid #cfcfcf;
    border-radius: 2px;
    background: #f7f7f7;
}

/* override MathJax center alignment in output cells */
div.nboutput div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.pngmath center alignment in output cells */
div.nboutput div.math p {
    text-align: left;
}

/* standard error */
div.nboutput div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast,
.nboutput.nblast {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast + .nbinput {
    margin-top: -19px;
}

/* nice headers on first paragraph of info/warning boxes */
.admonition .first {
    margin: -12px;
    padding: 6px 12px;
    margin-bottom: 12px;
    color: #fff;
    line-height: 1;
    display: block;
}
.admonition.warning .first {
    background: #f0b37e;
}
.admonition.note .first {
    background: #6ab0de;
}
.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}
</style>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [1]:
</pre></div>
</div>
<div class="input_area highlight-ipython2"><div class="highlight"><pre>
<span></span>%matplotlib inline
# import some dependencies
import numpy as np
import matplotlib.pyplot as plt
try:
    import seaborn as sns
    sns.set()
except ImportError:
    pass

import torch
from torch.autograd import Variable

import pyro
import pyro.infer
import pyro.optim
import pyro.distributions as dist

torch.manual_seed(101)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>Out[1]:
</pre></div>
</div>
<div class="output_area highlight-none"><div class="highlight"><pre>
<span></span>&lt;torch._C.Generator at 0x7f316f0ec5f0&gt;
</pre></div>
</div>
</div>
<div class="section" id="使用Pyro进行推断：-从随机函数到边缘分布">
<h1>使用Pyro进行推断： 从随机函数到边缘分布<a class="headerlink" href="#使用Pyro进行推断：-从随机函数到边缘分布" title="永久链接至标题">¶</a></h1>
<p>随机函数引入一个定义在隐变量<span class="math">\(z\)</span>
且返回值为<span class="math">\(y\)</span>的联合概率分布<span class="math">\(p(y, z \; \vert \; x)\)</span>
，并且这个联合概率分布能够求出对某个自变量的边缘分布。然而对于一个非参随机函数，我们不再需要显示计算条件概率<span class="math">\(p(y \; \vert \; x)\)</span>
或依照概率<span class="math">\(y \sim p (y \; \vert \; x)\)</span>从边缘分布中进行采样。</p>
<p>广义来说，像Pyro这样的通用概率编程语言，进行<em>推断</em>的难题在于如何在任意给定的逻辑约束下构造一个边缘分布，从而进行计算。这种约束既可以是一个带返回值的确定性函数，也可以是包含随机性，或者同时具备这两个特性。</p>
<p><em>贝叶斯推断</em>或者<em>后验概率推断</em>
是在可接受范围进行近似计算的普遍算法的一种特殊形式。在贝叶斯推断中，返回值通常是内部<code class="docutils literal"><span class="pre">样本</span></code>状态的一个子集，同时约束条件也是其他内部<code class="docutils literal"><span class="pre">样本</span></code>状态的等价约束。大部分现代机器学习算法都能够被视为一种近似贝叶斯推断，因此能够简洁的使用像Pyro这样的语言来表达。</p>
<p>接下来我们将构造一个简单物理问题的生成模型，并且使用Pyro的推断机制来解决它。</p>
<div class="section" id="一个简单的案例">
<h2>一个简单的案例<a class="headerlink" href="#一个简单的案例" title="永久链接至标题">¶</a></h2>
<p>假设我们想要知道一些物体的重量，但是我们使用的度量工具是不可信的，对同一个物体每次称重的值都有细微的差异。我们希望通过把多个有噪声的信息以及一些对物体先验知识，例如材料的密度和其他性质，综合起来考虑，以补偿这种由测量引入的随机性。下面这个模型表达了这个过程：</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [2]:
</pre></div>
</div>
<div class="input_area highlight-ipython2"><div class="highlight"><pre>
<span></span>def scale(guess):
    # 对重量的先验包含了我们猜测的不确定性
    weight = pyro.sample(&quot;weight&quot;, dist.normal, guess, Variable(torch.ones(1)))
    # 这包含了我们对度量工具噪音的先验
    # 度量结果会在真实重量周围震荡
    return pyro.sample(&quot;measurement&quot;, dist.normal, weight, Variable(torch.Tensor([0.75])))
</pre></div>
</div>
</div>
</div>
<div class="section" id="如何表示边缘分布">
<h2>如何表示边缘分布<a class="headerlink" href="#如何表示边缘分布" title="永久链接至标题">¶</a></h2>
<p>在使用模型来估计物体重量前，我们先分析一下我们模型的行为。实际上我们能够使用重要性采样来模拟一个以给定猜测作为先验的边缘分布。</p>
<p>Pyro中进行边缘化的操作<code class="docutils literal"><span class="pre">pyro.infer.Marginal</span></code>分为两步：首先我们利用模型生成一堆加权的执行结果，然后我们用这些执行结果生成一个由特定参数集约束的概率直方图。</p>
<p>生成执行结果的过程就是采样的过程，对模型而言只需要一些离散的隐变量，就像枚举那样。为了构造一个基本的重要性采样（使用先验作为初始分布），我们可以像这样写：</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [3]:
</pre></div>
</div>
<div class="input_area highlight-ipython2"><div class="highlight"><pre>
<span></span>posterior = pyro.infer.Importance(scale, num_samples=100)
</pre></div>
</div>
</div>
<p>虽然<code class="docutils literal"><span class="pre">posterior</span></code>能够被有经验的用户用来带参数的调用使<code class="docutils literal"><span class="pre">scale</span></code>能够采样出一个结果，但它本身并不是特别有用。相反，
<code class="docutils literal"><span class="pre">posterior</span></code>是被设计来给<code class="docutils literal"><span class="pre">pyro.infer.Marginal</span></code>使用的，后者能够以前者为输入产生一个输入输出类型和<code class="docutils literal"><span class="pre">scale</span></code>一致的随机原函数。</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [4]:
</pre></div>
</div>
<div class="input_area highlight-ipython2"><div class="highlight"><pre>
<span></span>guess = Variable(torch.Tensor([8.5]))

marginal = pyro.infer.Marginal(posterior)
print(marginal(guess))
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Variable containing:
 7.9588
[torch.FloatTensor of size 1]

</pre></div></div>
</div>
<p>当传入<code class="docutils literal"><span class="pre">guess</span></code>作为输入是，<code class="docutils literal"><span class="pre">marginal</span></code>首先会使用<code class="docutils literal"><span class="pre">posterior</span></code>对给定的<code class="docutils literal"><span class="pre">guess</span></code>产生一个带权值的执行结果序列，然后基于这些序列的返回值构造一个直方图，最后返回一个从这个直方图中抽取的样本。使用相同的参数反复调用<code class="docutils literal"><span class="pre">marginal</span></code>将从同一个直方图中采样。</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [5]:
</pre></div>
</div>
<div class="input_area highlight-ipython2"><div class="highlight"><pre>
<span></span>plt.hist([marginal(guess).data[0] for _ in range(100)], range=(5.0, 12.0))
plt.title(&quot;P(measurement | guess)&quot;)
plt.xlabel(&quot;weight&quot;)
plt.ylabel(&quot;#&quot;)
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>Out[5]:
</pre></div>
</div>
<div class="output_area highlight-none"><div class="highlight"><pre>
<span></span>&lt;matplotlib.text.Text at 0x7f3160ed6da0&gt;
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/intro_part_ii_9_1.png" src="_images/intro_part_ii_9_1.png" />
</div>
</div>
<p><code class="docutils literal"><span class="pre">pyro.infer.Marginal</span></code>也接受可选关键字参数列表<code class="docutils literal"><span class="pre">sites=[name1,</span> <span class="pre">name2,</span> <span class="pre">...]</span></code>来提供隐变量的名字。当<code class="docutils literal"><span class="pre">sites</span></code>被指定时，<code class="docutils literal"><span class="pre">marginal</span></code>将会返回一个字典，接受来自指定应变量列表名字的可选关键字，而对应值则为从单次执行结果中求得的值。当我们希望从一个后验对象中计算很多不同的边缘分布时，这将非常有用。</p>
</div>
<div class="section" id="基于数据的条件模型">
<h2>基于数据的条件模型<a class="headerlink" href="#基于数据的条件模型" title="永久链接至标题">¶</a></h2>
<p>The real utility of probabilistic programming is in the ability to
condition generative models on observed data and infer the latent
factors that might have produced that data. In Pyro, we separate the
expression of conditioning from its evaluation via inference, making it
possible to write a model once and condition it on many different
observations. Pyro supports constraining a model’s internal <code class="docutils literal"><span class="pre">sample</span></code>
statements to be equal to a given set of observations.</p>
<p>Consider <code class="docutils literal"><span class="pre">scale</span></code> once again. Suppose we want to sample from the
marginal distribution of <code class="docutils literal"><span class="pre">weight</span></code> given input <code class="docutils literal"><span class="pre">guess</span> <span class="pre">=</span> <span class="pre">0.5</span></code>, but now
we have observed that <code class="docutils literal"><span class="pre">measurement</span> <span class="pre">==</span> <span class="pre">0.1</span></code>. Pyro provides the function
<code class="docutils literal"><span class="pre">pyro.condition</span></code> to allow us to constrain the values of sample
statements. <code class="docutils literal"><span class="pre">pyro.condition</span></code> is a higher-order function that takes a
model and a dictionary of data and returns a new model that has the same
input and output signatures but always uses the given values at observed
<code class="docutils literal"><span class="pre">sample</span></code> statements:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [6]:
</pre></div>
</div>
<div class="input_area highlight-ipython2"><div class="highlight"><pre>
<span></span>conditioned_scale = pyro.condition(
    scale, data={&quot;measurement&quot;: Variable(torch.Tensor([8.5]))})
</pre></div>
</div>
</div>
<p>Because it behaves just like an ordinary Python function, conditioning
can be deferred or parametrized with Python’s <code class="docutils literal"><span class="pre">lambda</span></code> or <code class="docutils literal"><span class="pre">def</span></code>:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [7]:
</pre></div>
</div>
<div class="input_area highlight-ipython2"><div class="highlight"><pre>
<span></span>def deferred_conditioned_scale(measurement, *args, **kwargs):
    return pyro.condition(scale, data={&quot;measurement&quot;: measurement})(*args, **kwargs)
</pre></div>
</div>
</div>
<p>In some cases it might be more convenient to pass observations directly
to individual <code class="docutils literal"><span class="pre">pyro.sample</span></code> statements instead of using
<code class="docutils literal"><span class="pre">pyro.condition</span></code>. The optional <code class="docutils literal"><span class="pre">obs</span></code> keyword argument is reserved by
<code class="docutils literal"><span class="pre">pyro.sample</span></code> for that purpose; in addition, <code class="docutils literal"><span class="pre">pyro.observe</span></code> is an
alias for <code class="docutils literal"><span class="pre">pyro.sample</span></code> with <code class="docutils literal"><span class="pre">obs</span></code>:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [8]:
</pre></div>
</div>
<div class="input_area highlight-ipython2"><div class="highlight"><pre>
<span></span># equivalent to pyro.condition(scale, data={&quot;measurement&quot;: Variable(torch.ones(1))})
def scale_obs(guess):
    z = pyro.sample(&quot;weight&quot;, dist.normal, guess, Variable(torch.ones(1)))
     # here we attach an observation measurement == 1
    return pyro.sample(&quot;measurement&quot;, dist.normal, weight, Variable(torch.ones(1)),
                       obs=Variable(torch.Tensor([0.1])))

# equivalent to scale_obs:
def scale_obs(guess):
    z = pyro.sample(&quot;weight&quot;, dist.normal, guess, Variable(torch.ones(1)))
    # here we attach an observation measurement == 1
    return pyro.observe(&quot;measurement&quot;, dist.normal, Variable(torch.ones(1)),
                        weight, Variable(torch.Tensor([0.1])))
</pre></div>
</div>
</div>
<p>However, hardcoding is not usually recommended due to its invasive
non-compositional nature. By contrast, using <code class="docutils literal"><span class="pre">pyro.condition</span></code>,
conditioning may be composed freely to form multiple complex queries on
probabilistic models without modifying the underlying model. The only
restriction is that a single site may only be constrained once.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [9]:
</pre></div>
</div>
<div class="input_area highlight-ipython2"><div class="highlight"><pre>
<span></span>def scale2(guess):
    weight = pyro.sample(&quot;weight&quot;, dist.normal,
                         guess, Variable(torch.ones(1)))
    tolerance = torch.abs(
        pyro.sample(&quot;tolerance&quot;, dist.normal, Variable(torch.zeros(1)), Variable(torch.ones(1))))

    return pyro.sample(&quot;measurement&quot;, dist.normal, weight, tolerance)

# conditioning composes:
# the following are all equivalent and do not interfere with each other
conditioned_scale2_1 = pyro.condition(
    pyro.condition(scale2, data={&quot;weight&quot;: Variable(torch.ones(1))}),
    data={&quot;measurement&quot;: Variable(torch.ones(1))})

conditioned_scale2_2 = pyro.condition(
    pyro.condition(scale2, data={&quot;measurement&quot;: Variable(torch.ones(1))}),
    data={&quot;weight&quot;: Variable(torch.ones(1))})

conditioned_scale2_3 = pyro.condition(
    scale2, data={&quot;weight&quot;: Variable(torch.ones(1)), &quot;measurement&quot;: Variable(torch.ones(1))})
</pre></div>
</div>
</div>
<p>In addition to <code class="docutils literal"><span class="pre">pyro.condition</span></code> for incorporating observations, Pyro
also contains <code class="docutils literal"><span class="pre">pyro.do</span></code>, an implementation of Pearl’s <code class="docutils literal"><span class="pre">do</span></code>-operator
used for causal inference with an identical interface to
<code class="docutils literal"><span class="pre">pyro.condition</span></code>. <code class="docutils literal"><span class="pre">condition</span></code> and <code class="docutils literal"><span class="pre">do</span></code> can be mixed and composed
freely, making Pyro a powerful tool for model-based causal inference.
See the <a class="reference external" href="http://pyro.ai/examples/causal_inference.html">causal inference
tutorial</a> for more
details about <code class="docutils literal"><span class="pre">pyro.do</span></code> and a simple example of causal inference in a
model of disease diagnosis.</p>
</div>
<div class="section" id="Flexible-Approximate-Inference-With-Guide-Functions">
<h2>Flexible Approximate Inference With Guide Functions<a class="headerlink" href="#Flexible-Approximate-Inference-With-Guide-Functions" title="永久链接至标题">¶</a></h2>
<p>Let’s return to <code class="docutils literal"><span class="pre">deferred_conditioned_scale</span></code>. Now that we have
constrained <code class="docutils literal"><span class="pre">measurement</span></code> against some data, we can use Pyro’s
approximate inference algorithms to estimate the distribution over
<code class="docutils literal"><span class="pre">weight</span></code> given <code class="docutils literal"><span class="pre">guess</span></code> and <code class="docutils literal"><span class="pre">measurement</span> <span class="pre">==</span> <span class="pre">data</span></code>. We saw earlier
how to use importance sampling to do this for <code class="docutils literal"><span class="pre">scale</span></code>; we can use
exactly the same constructs with a conditioned model:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [10]:
</pre></div>
</div>
<div class="input_area highlight-ipython2"><div class="highlight"><pre>
<span></span>guess = Variable(torch.Tensor([8.5]))
measurement = Variable(torch.Tensor([9.5]))

conditioned_scale = pyro.condition(scale, data={&quot;measurement&quot;: measurement})

marginal = pyro.infer.Marginal(
    pyro.infer.Importance(conditioned_scale, num_samples=100), sites=[&quot;weight&quot;])

# The marginal distribution concentrates around the data
print(marginal(guess))
plt.hist([marginal(guess)[&quot;weight&quot;].data[0] for _ in range(100)], range=(5.0, 12.0))
plt.title(&quot;P(weight | measurement, guess)&quot;)
plt.xlabel(&quot;weight&quot;)
plt.ylabel(&quot;#&quot;)
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;weight&#39;: Variable containing:
 8.3751
[torch.FloatTensor of size 1]
}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>Out[10]:
</pre></div>
</div>
<div class="output_area highlight-none"><div class="highlight"><pre>
<span></span>&lt;matplotlib.text.Text at 0x7f3160df96d8&gt;
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/intro_part_ii_21_2.png" src="_images/intro_part_ii_21_2.png" />
</div>
</div>
<p>However, this approach is extremely computationally inefficient because
the prior distribution over <code class="docutils literal"><span class="pre">weight</span></code> may be very far from the true
distribution over weights, especially if our initial <code class="docutils literal"><span class="pre">guess</span></code> is not
very good.</p>
<p>Therefore, some inference algorithms in Pyro, like
<code class="docutils literal"><span class="pre">pyro.infer.Importance</span></code> and <code class="docutils literal"><span class="pre">pyro.infer.SVI</span></code>, allow us to use
arbitrary stochastic functions, which we will call <em>guide functions</em> or
<em>guides</em>, as approximate posterior distributions. Guide functions must
satisfy these two criteria to be valid approximations for a particular
model: 1. all unobserved sample statements that appear in the model
appear in the guide. 2. the guide has the same input signature as the
model (i.e.&nbsp;takes the same arguments)</p>
<p>Guide functions can serve as programmable, data-dependent proposal
distributions for importance sampling, rejection sampling, sequential
Monte Carlo, MCMC, and independent Metropolis-Hastings, and as
variational distributions or inference networks for stochastic
variational inference. Currently, only importance sampling and
stochastic variational inference are implemented in Pyro, but we plan to
add other algorithms in the future.</p>
<p>Although the precise meaning of the guide is different across different
inference algorithms, the guide function should generally be chosen so
that it closely approximates the distribution over all unobserved
<code class="docutils literal"><span class="pre">sample</span></code> statements in the model. The simplest guide for
<code class="docutils literal"><span class="pre">deferred_conditioned_scale</span></code> matches the prior distribution over
<code class="docutils literal"><span class="pre">weight</span></code>:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [11]:
</pre></div>
</div>
<div class="input_area highlight-ipython2"><div class="highlight"><pre>
<span></span>def scale_prior_guide(guess):
    return pyro.sample(&quot;weight&quot;, dist.normal, guess, Variable(torch.ones(1)))

posterior = pyro.infer.Importance(conditioned_scale,
                                  guide=scale_prior_guide,
                                  num_samples=10)

marginal = pyro.infer.Marginal(posterior, sites=[&quot;weight&quot;])
</pre></div>
</div>
</div>
<p>Can we do better than the prior? In the case of <code class="docutils literal"><span class="pre">scale</span></code>, it turns out
that the true posterior distribution over <code class="docutils literal"><span class="pre">weight</span></code> given <code class="docutils literal"><span class="pre">guess</span></code> and
<code class="docutils literal"><span class="pre">measurement</span></code> can be written directly as:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [12]:
</pre></div>
</div>
<div class="input_area highlight-ipython2"><div class="highlight"><pre>
<span></span>def scale_posterior_guide(measurement, guess):
    # note that torch.size(measurement, 0) is the total number of measurements
    # that we&#39;re conditioning on
    a = (guess + torch.sum(measurement)) / (measurement.size(0) + 1.0)
    b = Variable(torch.ones(1)) / (measurement.size(0) + 1.0)
    return pyro.sample(&quot;weight&quot;, dist.normal, a, b)

posterior = pyro.infer.Importance(deferred_conditioned_scale,
                                  guide=scale_posterior_guide,
                                  num_samples=20)

marginal = pyro.infer.Marginal(posterior, sites=[&quot;weight&quot;])
plt.hist([marginal(measurement, guess)[&quot;weight&quot;].data[0] for _ in range(100)], range=(5.0, 12.0))
plt.title(&quot;P(weight | measurement, guess)&quot;)
plt.xlabel(&quot;weight&quot;)
plt.ylabel(&quot;#&quot;)
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>Out[12]:
</pre></div>
</div>
<div class="output_area highlight-none"><div class="highlight"><pre>
<span></span>&lt;matplotlib.text.Text at 0x7f3160cdd710&gt;
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/intro_part_ii_25_1.png" src="_images/intro_part_ii_25_1.png" />
</div>
</div>
</div>
<div class="section" id="Parametrized-Stochastic-Functions-and-Variational-Inference">
<h2>Parametrized Stochastic Functions and Variational Inference<a class="headerlink" href="#Parametrized-Stochastic-Functions-and-Variational-Inference" title="永久链接至标题">¶</a></h2>
<p>Although we could write out the exact posterior distribution for
<code class="docutils literal"><span class="pre">scale</span></code>, in general it is intractable to specify a guide that is a
good approximation to the posterior distribution of an arbitrary
conditioned stochastic function. What we can do instead is use the
top-level function <code class="docutils literal"><span class="pre">pyro.param</span></code> to specify a <em>family</em> of guides
indexed by named parameters, and search for the member of that family
that is the best approximation. This approach to approximate posterior
inference is called <em>variational inference</em>.</p>
<p><code class="docutils literal"><span class="pre">pyro.param</span></code> is a frontend for Pyro’s key-value <em>parameter store</em>,
which is described in more detail in the documentation. Like
<code class="docutils literal"><span class="pre">pyro.sample</span></code>, <code class="docutils literal"><span class="pre">pyro.param</span></code> is always called with a name as its
first argument. The first time <code class="docutils literal"><span class="pre">pyro.param</span></code> is called with a
particular name, it stores its argument in the parameter store and then
returns that value. After that, when it is called with that name, it
returns the value from the parameter store regardless of any other
arguments. It is similar to <code class="docutils literal"><span class="pre">simple_param_store.setdefault</span></code> here, but
with some additional tracking and management functionality.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">simple_param_store</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">simple_param_store</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
<p>For example, we can parametrize <code class="docutils literal"><span class="pre">a</span></code> and <code class="docutils literal"><span class="pre">b</span></code> in
<code class="docutils literal"><span class="pre">scale_posterior_guide</span></code> instead of specifying them by hand:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [13]:
</pre></div>
</div>
<div class="input_area highlight-ipython2"><div class="highlight"><pre>
<span></span>def scale_parametrized_guide(guess):
    a = pyro.param(&quot;a&quot;, Variable(torch.randn(1) + guess.data.clone(), requires_grad=True))
    b = pyro.param(&quot;b&quot;, Variable(torch.randn(1), requires_grad=True))
    return pyro.sample(&quot;weight&quot;, dist.normal, a, torch.abs(b))
</pre></div>
</div>
</div>
<p>Pyro is built to enable <em>stochastic variational inference</em>, a powerful
and widely applicable class of variational inference algorithms with
three key characteristics: 1. Parameters are always real-valued tensors
2. We compute Monte Carlo estimates of a loss function from samples of
execution histories of the model and guide 3. We use stochastic gradient
descent to search for the optimal parameters.</p>
<p>Combining stochastic gradient descent with PyTorch’s GPU-accelerated
tensor math and automatic differentiation allows us to scale variational
inference to very high-dimensional parameter spaces and massive
datasets.</p>
<p>Pyro’s SVI functionality is described in detail in the <a class="reference external" href="http://pyro.ai/examples/svi_part_i.html">SVI
tutorial</a>. Here is a very
simple example applying it to <code class="docutils literal"><span class="pre">scale</span></code>:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [14]:
</pre></div>
</div>
<div class="input_area highlight-ipython2"><div class="highlight"><pre>
<span></span>pyro.clear_param_store()
svi = pyro.infer.SVI(model=conditioned_scale,
                     guide=scale_parametrized_guide,
                     optim=pyro.optim.SGD({&quot;lr&quot;: 0.001}),
                     loss=&quot;ELBO&quot;)

losses = []
for t in range(1000):
    losses.append(svi.step(guess))

plt.plot(losses)
plt.title(&quot;ELBO&quot;)
plt.xlabel(&quot;step&quot;)
plt.ylabel(&quot;loss&quot;)
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>Out[14]:
</pre></div>
</div>
<div class="output_area highlight-none"><div class="highlight"><pre>
<span></span>&lt;matplotlib.text.Text at 0x7f316037f198&gt;
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/intro_part_ii_29_1.png" src="_images/intro_part_ii_29_1.png" />
</div>
</div>
<p>Note that optimization will update the guide parameters, but does not
produce a posterior distribution object itself. Once we find good
parameter values, we can just use the guide as a representation of the
model’s approximate posterior for downstream tasks.</p>
<p>For example, we can use the optimized guide as an importance
distribution for estimating the marginal distribution over <code class="docutils literal"><span class="pre">weight</span></code>
with many fewer samples than the prior:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [15]:
</pre></div>
</div>
<div class="input_area highlight-ipython2"><div class="highlight"><pre>
<span></span>posterior = pyro.infer.Importance(conditioned_scale, scale_parametrized_guide, num_samples=10)
marginal = pyro.infer.Marginal(posterior, sites=[&quot;weight&quot;])

plt.hist([marginal(guess)[&quot;weight&quot;].data[0] for _ in range(100)], range=(5.0, 12.0))
plt.title(&quot;P(weight | measurement, guess)&quot;)
plt.xlabel(&quot;weight&quot;)
plt.ylabel(&quot;#&quot;)
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>Out[15]:
</pre></div>
</div>
<div class="output_area highlight-none"><div class="highlight"><pre>
<span></span>&lt;matplotlib.text.Text at 0x7f31602fb3c8&gt;
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/intro_part_ii_31_1.png" src="_images/intro_part_ii_31_1.png" />
</div>
</div>
<p>我们能够把guide当成一个近似后验直接采样。</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [16]:
</pre></div>
</div>
<div class="input_area highlight-ipython2"><div class="highlight"><pre>
<span></span>plt.hist([scale_parametrized_guide(guess).data[0] for _ in range(100)], range=(5.0, 12.0))
plt.title(&quot;P(weight | measurement, guess)&quot;)
plt.xlabel(&quot;weight&quot;)
plt.ylabel(&quot;#&quot;)
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>Out[16]:
</pre></div>
</div>
<div class="output_area highlight-none"><div class="highlight"><pre>
<span></span>&lt;matplotlib.text.Text at 0x7f3160236940&gt;
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/intro_part_ii_33_1.png" src="_images/intro_part_ii_33_1.png" />
</div>
</div>
</div>
<div class="section" id="下一步">
<h2>下一步<a class="headerlink" href="#下一步" title="永久链接至标题">¶</a></h2>
<p>在<a class="reference external" href="https://online-translation.github.io/pyro-translation.github.io/vae.html">变分自编码器教程</a>,
我们将会看到像<code class="docutils literal"><span class="pre">scale</span></code>这样的模型是如何被组织到深度神经网络中，并且使用随机变分推断来构造一个图像的生成模型的。</p>
</div>
</div>


           </div>
           <div class="articleComments">
            
           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="svi_part_i.html" class="btn btn-neutral float-right" title="SVI Part I: An Introduction to Stochastic Variational Inference in Pyro" accesskey="n" rel="next">下一章 <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="intro_part_i.html" class="btn btn-neutral" title="Pyro里的模型：从原分布到随机函数" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> 上一章</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2017, 小熊.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'./',
            VERSION:'0.1.0',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="_static/jquery.js"></script>
      <script type="text/javascript" src="_static/underscore.js"></script>
      <script type="text/javascript" src="_static/doctools.js"></script>
      <script type="text/javascript" src="_static/translations.js"></script>
      <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>