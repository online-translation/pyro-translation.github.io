{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 加载一些重要的依赖\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pyro里的模型：从原分布到随机函数\n",
    "\n",
    "Pyro项目的这个基础模块叫做 _随机函数_。这是一个包含两种元素的Python可调用模块。\n",
    "\n",
    "- 确定性Python代码；和\n",
    "- 若干初等随机函数\n",
    "\n",
    "具体而言，一个随机函数就是一个包含`__call__()`方法的Python对象，就像一个函数，一种方法，或者一个PyTorch的`nn.Module`。\n",
    "\n",
    "在这个教程和文档里，我们通常把随机函数称为**模型**，因为随机函数也可以被用来表示一个数据生成的简单或者抽象的过程描述。用随机函数来表征模型在Pyro中通常意味着模型能够像其他通用的Python可调用模块一样被重组、复用、载入和序列化。\n",
    "\n",
    "话不多说，让我们开始介绍我们第一个基础的元件：初等随机函数：\n",
    "\n",
    "\n",
    "## 随机原函数\n",
    "\n",
    "随机原函数，也叫分布函数，就是一类重要的随机函数，我们能够显式计算给定输入的输出值的概率。Pyro自带一个独立的[函数库](http://docs.pyro.ai/distributions.html), 'pyro.distribution'，这是一个基于PyTorch构建的GPU加速的多变量概率分布函数库，提供很多分布函数族，例如：伯努利分布、均匀分布。用户也能够使用子类`pyro.distributions.Distribution`来实现经典的分布。\n",
    "\n",
    "使用随机原函数是非常简单的。例如，从一个标准正态分布$\\\\mathcal{N}(0,1)$中抽取一个样本`x`,我们只需要像下面这样做："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 1.6869\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mu = Variable(torch.zeros(1))   # 均值为0\n",
    "sigma = Variable(torch.ones(1)) # 单位方差\n",
    "x = dist.normal(mu, sigma)      # x 是分布 N(0,1)的一个样本\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意，`dis.normal`是一个带参数的函数，`dist.normal(...)`返回一个样本。需要注意的是，传递给`dist.normal`的参数需要是PyTorch的`Variable`.这是必要的因为我们想利用PyTorch快速张量计算和自动求导能力。为了求样本`x`的值，例如根据分布$\\\\mathcal{N}(0,1)$计算他的log概率值，我们只需要这样做："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "-2.3417\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_p_x = dist.normal.log_pdf(x, mu, sigma)\n",
    "print(log_p_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意，传递到方法`log_pdf`的参数是：首先是需要求值的变量（例如`x`）,接下来是这个分布的参数（例如`mu`和`sigma`）。\n",
    "\n",
    "## 原函数 `pyro.sample`\n",
    "\n",
    "`pyro.sample`是Pyro众多核心语法原函数(the core language primitives)中的一个。使用`pyro.sample`就像调用一个随机原函数那样简单，但是有一个重要的差异："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "-0.8290\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = pyro.sample(\"my_sample\", dist.normal, mu, sigma)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "就像直接调用 `dist.normal`，这里会返回一个从标准正态分布中抽取的样本。关键的不同点在于：这个样本被命名了。Pyro的后端使用这些名字来唯一标识样本，并且在运行时根据这些闭包随机函数被使用的方式来改变他们的行为。我们将会看到，这是Pyro能够实现在推断算法上做多重操作的原因。 \n",
    "\n",
    "我们已经展示了`pyro.sample`是如何和像`dist.normal`这样的随机原函数进行交互的。这和任意其他随机函数`fn()`没什么不同。例如我们可能会有这样的代码:\n",
    "\n",
    "```python\n",
    "x = pyro.sample(\"my_sample\", fn, arg1, arg2)\n",
    "```\n",
    "\n",
    "这将会创建一个被命名的mysample，且从函数`fn`中以`arg1` 和 `arg2`为参数进行采样得到的样本。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一个简单的模型\n",
    "\n",
    "到目前为止我们已经介绍了`pyro.sample` 和 `pyro.distributions`，我们已经能够编写一个简单的模型了。我们对真实世界建模的渴望驱使着我们对概率编程产生狂热的兴趣，那么我们选择一个具体的案例吧。\n",
    "\n",
    "假设我们有一堆日气温平均值和云层覆盖的数据，我们想知道温度和晴天或多云天气之间是如何关联的。一个简单的随机函数如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('sunny', 62.1190299987793)\n",
      "('cloudy', 58.74806213378906)\n",
      "('sunny', 79.73405456542969)\n"
     ]
    }
   ],
   "source": [
    "def weather():\n",
    "    cloudy = pyro.sample('cloudy', dist.bernoulli, \n",
    "                         Variable(torch.Tensor([0.3])))\n",
    "    cloudy = 'cloudy' if cloudy.data[0] == 1.0 else 'sunny'\n",
    "    mean_temp = {'cloudy': [55.0], 'sunny': [75.0]}[cloudy]\n",
    "    sigma_temp = {'cloudy': [10.0], 'sunny': [15.0]}[cloudy]\n",
    "    temp = pyro.sample('temp', dist.normal,\n",
    "                       Variable(torch.Tensor(mean_temp)), \n",
    "                       Variable(torch.Tensor(sigma_temp)))\n",
    "    return cloudy, temp.data[0]\n",
    "\n",
    "for _ in range(3):\n",
    "    print(weather())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "让我们一行行的来看这些代码。首先，在2-3行，我们使用了`pyro.sample`来定义一个二值随机变量'coudy'，这是一个以参数0.3从伯努利分布中抽取的一个样本。由于伯努利分布只会返回`0`和`1`，在第4行我们把'coudy'的值转换成一个字符串，这样'weather'函数的返回值就变得容易理解。依照我们定义的模型，30%的概率会是多云天气，70%的天气会是晴天。\n",
    "\n",
    "\n",
    "Since the bernoulli distributions returns `0`s or `1`s, in line 4 we convert the value `cloud` to a string so that return values of `weather` are easier to parse. So according to this model 30% of the time it's cloudy and 70% of the time it's sunny.\n",
    "\n",
    "In lines 5-6 we define the parameters we're going to use to sample the temperature in lines 7-9. These parameters depend on the particular value of `cloudy` we sampled in line 2. For example, the mean temperature is 55 degrees (Fahrenheit) on cloudy days and 75 degrees on sunny days. Finally we return the two values `cloudy` and `temp` in line 10.\n",
    "\n",
    "Procedurally, `weather()` is a non-deterministic Python callable that returns two random samples. Because the randomness is invoked with `pyro.sample`, however, it is much more than that. In particular `weather()` specifies a joint probability distribution over two named random variables: `cloudy` and `temp`. As such, it defines a probabilistic model that we can reason about using the techniques of probability theory. For example we might ask: if I observe a temperature of 70 degrees, how likely is it to be cloudy? How to formulate and answer these kinds of questions will be the subject of the next tutorial.\n",
    "\n",
    "We've now seen how to define a simple model. Building off of it is easy. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ice_cream_sales():\n",
    "    cloudy, temp = weather()\n",
    "    expected_sales = [200] if cloudy == 'sunny' and temp > 80.0 else [50]\n",
    "    ice_cream = pyro.sample('ice_cream', dist.normal, \n",
    "                            Variable(torch.Tensor(expected_sales)),\n",
    "                            Variable(torch.Tensor([10.0])))\n",
    "    return ice_cream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This kind of modularity, familiar to any programmer, is obviously very powerful. But is it powerful enough to encompass all the different kinds of models we'd like to express?\n",
    "\n",
    "## Universality: Stochastic Recursion, Higher-order Stochastic Functions, and Random Control Flow\n",
    "\n",
    "Because Pyro is embedded in Python, stochastic functions can contain arbitrarily complex deterministic Python and randomness can freely affect control flow. For example, we can construct recursive functions that terminate their recursion nondeterministically, provided we take care to pass `pyro.sample` unique sample names whenever it's called. For example we can define a geometric distribution like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def geometric(p, t=None):\n",
    "    if t is None:\n",
    "        t = 0\n",
    "    x = pyro.sample(\"x_{}\".format(t), dist.bernoulli, p)\n",
    "    if torch.equal(x.data, torch.zeros(1)):\n",
    "        return x\n",
    "    else:\n",
    "        return x + geometric(p, t+1)\n",
    "    \n",
    "print(geometric(Variable(torch.Tensor([0.5]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the names `x_0`, `x_1`, etc., in `geometric()` are generated dynamically and that different executions can have different numbers of named random variables. \n",
    "\n",
    "We are also free to define stochastic functions that accept as input or produce as output other stochastic functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0.8229\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def normal_product(mu, sigma):\n",
    "    z1 = pyro.sample(\"z1\", dist.normal, mu, sigma)\n",
    "    z2 = pyro.sample(\"z2\", dist.normal, mu, sigma)\n",
    "    y = z1 * z2\n",
    "    return y\n",
    "\n",
    "def make_normal_normal():\n",
    "    mu_latent = pyro.sample(\"mu_latent\", dist.normal, \n",
    "                            Variable(torch.zeros(1)), \n",
    "                            Variable(torch.ones(1)))\n",
    "    fn = lambda sigma: normal_product(mu_latent, sigma)\n",
    "    return fn\n",
    "\n",
    "print(make_normal_normal()(Variable(torch.ones(1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here `make_normal_normal()` is a stochastic function that takes one argument and which, upon execution, generates three named random variables.\n",
    "\n",
    "The fact that Pyro supports arbitrary Python code like this&mdash;iteration, recursion, higher-order functions, etc.&mdash;in conjuction with random control flow means that Pyro stochastic functions are _universal_, i.e. they can be used to represent any computable probability distribution. As we will see in subsequent tutorials, this is incredibly powerful. \n",
    "\n",
    "It is worth emphasizing that this is one reason why Pyro is built on top of PyTorch: dynamic computational graphs are an important ingredient in allowing for universal models that can benefit from GPU-accelerated tensor math."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Next Steps\n",
    "\n",
    "We've shown how we can use stochastic functions and primitive distributions to represent models in Pyro. In order to learn models from data and reason about them we need to be able to do inference. This is the subject of the [next tutorial](http://pyro.ai/examples/intro_part_ii.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
