

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>The Semi-Supervised VAE &mdash; Pyro实例与教程 0.1.0 documentation</title>
  

  
  
  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  

  

  
        <link rel="index" title="Index"
              href="genindex.html"/>
        <link rel="search" title="Search" href="search.html"/>
    <link rel="top" title="Pyro实例与教程 0.1.0 documentation" href="index.html"/>
        <link rel="prev" title="Attend Infer Repeat" href="air.html"/> 

  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="index.html" class="icon icon-home"> Pyro实例与教程
          

          
          </a>

          
            
            
              <div class="version">
                0.1.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="intro_part_i.html">Pyro里的模型：从原分布到随机函数</a></li>
<li class="toctree-l1"><a class="reference internal" href="intro_part_ii.html">Inference in Pyro: From Stochastic Functions to Marginal Distributions</a></li>
<li class="toctree-l1"><a class="reference internal" href="svi_part_i.html">SVI Part I: An Introduction to Stochastic Variational Inference in Pyro</a></li>
<li class="toctree-l1"><a class="reference internal" href="svi_part_ii.html">SVI Part II: Conditional Independence, Subsampling, and Amortization</a></li>
<li class="toctree-l1"><a class="reference internal" href="svi_part_iii.html">SVI Part III: ELBO Gradient Estimators</a></li>
<li class="toctree-l1"><a class="reference internal" href="vae.html">Variational Autoencoders</a></li>
<li class="toctree-l1"><a class="reference internal" href="bayesian_regression.html">Bayesian Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="dmm.html">Deep Markov Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="air.html">Attend Infer Repeat</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">The Semi-Supervised VAE</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#Introduction">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="#The-Challenges-of-Inference">The Challenges of Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="#First-Variant:-Standard-objective-function,-naive-estimator">First Variant: Standard objective function, naive estimator</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Network-Definitions">Network Definitions</a></li>
<li class="toctree-l3"><a class="reference internal" href="#MNIST-Pre-Processing">MNIST Pre-Processing</a></li>
<li class="toctree-l3"><a class="reference internal" href="#The-Objective-Function">The Objective Function</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#Interlude:-Summing-Out-Discrete-Latents">Interlude: Summing Out Discrete Latents</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Second-Variant:-Standard-Objective-Function,-Better-Estimator">Second Variant: Standard Objective Function, Better Estimator</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Third-Variant:-Adding-a-Term-to-the-Objective">Third Variant: Adding a Term to the Objective</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Results">Results</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Latent-Space-Visualization">Latent Space Visualization</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Conditional-image-generation">Conditional image generation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#Final-thoughts">Final thoughts</a></li>
<li class="toctree-l2"><a class="reference internal" href="#References">References</a></li>
</ul>
</li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Pyro实例与教程</a>
        
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>The Semi-Supervised VAE</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/ss-vae.ipynb.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput,
div.nbinput div.prompt,
div.nbinput div.input_area,
div.nbinput div[class*=highlight],
div.nbinput div[class*=highlight] pre,
div.nboutput,
div.nbinput div.prompt,
div.nbinput div.output_area,
div.nboutput div[class*=highlight],
div.nboutput div[class*=highlight] pre {
    background: none;
    border: none;
    padding: 0 0;
    margin: 0;
    box-shadow: none;
}

/* avoid gaps between output lines */
div.nboutput div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput,
div.nboutput {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput,
    div.nboutput {
        flex-direction: column;
    }
}

/* input container */
div.nbinput {
    padding-top: 5px;
}

/* last container */
div.nblast {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput div.prompt pre {
    color: #303F9F;
}

/* output prompt */
div.nboutput div.prompt pre {
    color: #D84315;
}

/* all prompts */
div.nbinput div.prompt,
div.nboutput div.prompt {
    min-width: 8ex;
    padding-top: 0.4em;
    padding-right: 0.4em;
    text-align: right;
    flex: 0;
}
@media (max-width: 540px) {
    div.nbinput div.prompt,
    div.nboutput div.prompt {
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput div.prompt.empty {
        padding: 0;
    }
}

/* disable scrollbars on prompts */
div.nbinput div.prompt pre,
div.nboutput div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput div.input_area,
div.nboutput div.output_area {
    padding: 0.4em;
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput div.input_area,
    div.nboutput div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput div.input_area {
    border: 1px solid #cfcfcf;
    border-radius: 2px;
    background: #f7f7f7;
}

/* override MathJax center alignment in output cells */
div.nboutput div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.pngmath center alignment in output cells */
div.nboutput div.math p {
    text-align: left;
}

/* standard error */
div.nboutput div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast,
.nboutput.nblast {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast + .nbinput {
    margin-top: -19px;
}

/* nice headers on first paragraph of info/warning boxes */
.admonition .first {
    margin: -12px;
    padding: 6px 12px;
    margin-bottom: 12px;
    color: #fff;
    line-height: 1;
    display: block;
}
.admonition.warning .first {
    background: #f0b37e;
}
.admonition.note .first {
    background: #6ab0de;
}
.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}
</style>
<div class="section" id="The-Semi-Supervised-VAE">
<h1>The Semi-Supervised VAE<a class="headerlink" href="#The-Semi-Supervised-VAE" title="Permalink to this headline">¶</a></h1>
<div class="section" id="Introduction">
<h2>Introduction<a class="headerlink" href="#Introduction" title="Permalink to this headline">¶</a></h2>
<p>Most of the models we’ve covered in the tutorials are unsupervised:</p>
<ul class="simple">
<li><a class="reference external" href="http://pyro.ai/examples/vae.html">Variational Autoencoder (VAE)</a></li>
<li><a class="reference external" href="http://pyro.ai/examples/dmm.html">DMM</a></li>
<li><a class="reference external" href="http://pyro.ai/examples/air.html">Attend-Infer-Repeat</a></li>
</ul>
<p>We’ve also covered a simple supervised model:</p>
<ul class="simple">
<li><a class="reference external" href="http://pyro.ai/examples/bayesian_regression.html">Bayesian
Regression</a></li>
</ul>
<p>The semi-supervised setting represents an interesting intermediate case
where some of the data is labeled and some is not. It is also of great
practical importance, since we often have very little labeled data and
much more unlabeled data. We’d clearly like to leverage unlabeled data
to improve our models of the labeled data.</p>
<p>The semi-supervised setting is also well suited to generative models,
where missing data can be accounted for quite naturally—at least
conceptually. As we will see, in restricting our attention to
semi-supervised generative models, there will be no shortage of
different model variants and possible inference strategies. Although
we’ll only be able to explore a few of these variants in detail, the
reader is likely to come away from the tutorial with a greater
appreciation for the abstractions and modularity offered by
probabilistic programming.</p>
<p>So let’s go about building a generative model. We have a dataset
<span class="math">\(\mathcal{D}\)</span> with <span class="math">\(N\)</span> datapoints,</p>
<div class="math">
\[\mathcal{D} = \{ ({\bf x}_i, {\bf y}_i) \}\]</div>
<p>where the <span class="math">\(\{ {\bf x}_i \}\)</span> are always observed and the labels
<span class="math">\(\{ {\bf y}_i \}\)</span> are only observed for some subset of the data.
Since we want to be able to model complex variations in the data, we’re
going to make this a latent variable model with a local latent variable
<span class="math">\({\bf z}_i\)</span> private to each pair <span class="math">\(({\bf x}_i, {\bf y}_i)\)</span>.
Even with this set of choices, a number of model variants are possible:
we’re going to focus on the model variant depicted in Figure 1 (this is
model M2 in reference [1]).</p>
<center><figure><img src="_static/img/ss_vae_m2.png" style="width: 180px;"><center><figcaption> <font size="+1"><b>Figure 1</b>: our semi-supervised generative model </font>(c.f. model M2 in reference [1])</figcaption></center></figure></center><p>For convenience—and since we’re going to model MNIST in our experiments
below—let’s suppose the <span class="math">\(\{ {\bf x}_i \}\)</span> are images and the
<span class="math">\(\{ {\bf y}_i \}\)</span> are digit labels. In this model setup, the
latent random variable <span class="math">\({\bf z}_i\)</span> and the (partially observed)
digit label <em>jointly</em> generate the observed image. The <span class="math">\({\bf z}_i\)</span>
represents <em>everything but</em> the digit label, possibly handwriting style
or position. Let’s sidestep asking when we expect this particular
factorization of <span class="math">\(({\bf x}_i, {\bf y}_i, {\bf z}_i)\)</span> to be
appropriate, since the answer to that question will depend in large part
on the dataset in question (among other things). Let’s instead highlight
some of the ways that inference in this model will be challenging as
well as some of the solutions that we’ll be exploring in the rest of the
tutorial.</p>
</div>
<div class="section" id="The-Challenges-of-Inference">
<h2>The Challenges of Inference<a class="headerlink" href="#The-Challenges-of-Inference" title="Permalink to this headline">¶</a></h2>
<p>For concreteness we’re going to continue to assume that the
partially-observed <span class="math">\(\{ {\bf y}_i \}\)</span> are discrete labels; we will
also assume that the <span class="math">\(\{ {\bf z}_i \}\)</span> are continuous.</p>
<ul class="simple">
<li>If we apply the general recipe for stochastic variational inference
to our model (e.g.&nbsp;see <a class="reference external" href="http://pyro.ai/examples/svi_part_i.html">SVI Part
I</a>) we’re going to be
sampling the discrete (and thus non-reparameterizable) variable
<span class="math">\({\bf y}_i\)</span> whenever it’s unobserved. As discussed in <a class="reference external" href="http://pyro.ai/examples/svi_part_i.html">SVI Part
III</a> this will generally
lead to high-variance gradient estimates.</li>
<li>A common way to ameliorate this problem—and one we’ll explore
below—is to forego sampling and instead sum out all ten values of the
class label <span class="math">\({\bf y}_i\)</span> when we calculate the ELBO for an
unlabeled datapoint <span class="math">\({\bf x}_i\)</span>. This is more expensive per
step, but can help us reduce the variance of our gradient estimator
and thereby take fewer steps</li>
<li>Recall that the role of the guide is to ‘fill in’ <em>latent</em> random
variables. Concretely, one component of our guide will be a digit
classifier <span class="math">\(q_\phi({\bf y} | {\bf x})\)</span> that will randomly ‘fill
in’ labels <span class="math">\(\{ {\bf y}_i \}\)</span> given an image
<span class="math">\(\{ {\bf x}_i \}\)</span>. Crucially, this means that the only term in
the ELBO that will depend on <span class="math">\(q_\phi(\cdot | {\bf x})\)</span> is the
term that involves a sum over <em>unlabeled</em> datapoints. This means that
our classifier <span class="math">\(q_\phi(\cdot | {\bf x})\)</span>—which in many cases
will be the primary object of interest—will not be learning from the
labeled datapoints (at least not directly)</li>
<li>This seems like a potential problem. Luckily, various fixes are
possible. Below we’ll follow the approach in reference [1], which
involves introducing an additional objective function for the
classifier to ensure that the classifier learns directly from the
labeled data</li>
</ul>
<p>We have our work cut out for us so let’s get started!</p>
</div>
<div class="section" id="First-Variant:-Standard-objective-function,-naive-estimator">
<h2>First Variant: Standard objective function, naive estimator<a class="headerlink" href="#First-Variant:-Standard-objective-function,-naive-estimator" title="Permalink to this headline">¶</a></h2>
<p>As discussed in the introduction, we’re considering the model depicted
in Figure 1. In more detail, the model has the following structure:</p>
<ul class="simple">
<li><span class="math">\(p({\bf y}) = Cat({\bf y}~|~{\bf \pi})\)</span>: multinomial (or
categorical) prior for the class label</li>
<li><span class="math">\(p({\bf z}) = \mathcal{N}({\bf z}~|~{\bf 0,I})\)</span>: unit normal
prior for the latent code <span class="math">\(\bf z\)</span></li>
<li><span class="math">\(p_{\theta}({\bf x}~|~{\bf z,y}) = Bernoulli\left({\bf x}~|~\mu\left({\bf z,y}\right)\right)\)</span>:
parameterized Bernoulli likelihood function;
<span class="math">\(\mu\left({\bf z,y}\right)\)</span> corresponds to <code class="docutils literal"><span class="pre">decoder</span></code> in the
code</li>
</ul>
<p>We structure the components of our guide <span class="math">\(q_{\phi}(.)\)</span> as follows:</p>
<ul class="simple">
<li><span class="math">\(q_{\phi}({\bf y}~|~{\bf x}) = Cat({\bf y}~|~{\bf \alpha}_{\phi}\left({\bf x}\right))\)</span>:
parameterized multinomial (or categorical) distribution;
<span class="math">\({\bf \alpha}_{\phi}\left({\bf x}\right)\)</span> corresponds to
<code class="docutils literal"><span class="pre">encoder_y</span></code> in the code</li>
<li><span class="math">\(q_{\phi}({\bf z}~|~{\bf x, y}) = \mathcal{N}({\bf z}~|~{\bf \mu}_{\phi}\left({\bf x, y}\right), {\bf \sigma^2_{\phi}\left(x, y\right)})\)</span>:
parameterized normal distribution;
<span class="math">\({\bf \mu}_{\phi}\left({\bf x, y}\right)\)</span> and
<span class="math">\({\bf \sigma^2_{\phi}\left(x, y\right)}\)</span> correspond to the
neural digit classifier <code class="docutils literal"><span class="pre">encoder_z</span></code> in the code</li>
</ul>
<p>These choices reproduce the structure of model M2 and its corresponding
inference network in reference [1].</p>
<p>We translate this model and guide pair into Pyro code below. Note that:</p>
<ul class="simple">
<li>The labels <code class="docutils literal"><span class="pre">ys</span></code>, which are represented with a one-hot encoding, are
only partially observed (<code class="docutils literal"><span class="pre">None</span></code> denotes unobserved values).</li>
<li><code class="docutils literal"><span class="pre">model()</span></code> handles both the observed and unobserved case.</li>
<li>The code assumes that <code class="docutils literal"><span class="pre">xs</span></code> and <code class="docutils literal"><span class="pre">ys</span></code> are mini-batches of images
and labels, respectively, with the size of each batch denoted by
<code class="docutils literal"><span class="pre">batch_size</span></code>.</li>
</ul>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [2]:
</pre></div>
</div>
<div class="input_area highlight-ipython2"><div class="highlight"><pre>
<span></span>def model(xs, ys=None):
    # sample z from the prior
    prior_mu = Variable(torch.zeros([batch_size, z_dim]))
    prior_sigma = Variable(torch.ones([batch_size, z_dim]))
    zs = pyro.sample(&quot;z&quot;, dist.normal, prior_mu, prior_sigma)

    # if the label y is observed, sample from the prior.
    # otherwise, observe the value
    alpha_prior = Variable(torch.ones([batch_size, 10]) / (10.))
    if ys is None:
        ys = pyro.sample(&quot;y&quot;, dist.categorical, alpha_prior)
    else:
        pyro.observe(&quot;y&quot;, dist.categorical, ys, alpha_prior)

    # finally, score the image x against the
    # parameterized distribution p(x|y,z) = bernoulli(decoder(y,z))
    mu = decoder.forward([zs, ys])
    pyro.observe(&quot;x&quot;, dist.bernoulli, xs, mu)

def guide(self, xs, ys=None):
    # if the class label is not observed, sample
    # with the variational distribution
    # q(y|x) = categorical(alpha(x))
    if ys is None:
        alpha = encoder_y.forward(xs)
        ys = pyro.sample(&quot;y&quot;, dist.categorical, alpha)

    # sample the latent z with the variational
    # distribution q(z|x,y) = normal(mu(x,y),sigma(x,y))
    mu, sigma = encoder_z.forward([xs, ys])
    zs = pyro.sample(&quot;z&quot;, dist.normal, mu, sigma)
</pre></div>
</div>
</div>
<div class="section" id="Network-Definitions">
<h3>Network Definitions<a class="headerlink" href="#Network-Definitions" title="Permalink to this headline">¶</a></h3>
<p>In our experiments we use the same network configurations as used in
reference [1]. The encoder and decoder networks have one hidden layer
with <span class="math">\(500\)</span> hidden units and softplus activation functions. We use
softmax as the activation function for the output of <code class="docutils literal"><span class="pre">encoder_y</span></code>,
sigmoid as the output activation function for <code class="docutils literal"><span class="pre">decoder</span></code> and
exponentiation for the sigma part of the output of <code class="docutils literal"><span class="pre">encoder_z</span></code>. The
latent dimension is 50.</p>
</div>
<div class="section" id="MNIST-Pre-Processing">
<h3>MNIST Pre-Processing<a class="headerlink" href="#MNIST-Pre-Processing" title="Permalink to this headline">¶</a></h3>
<p>We normalize the pixel values to the range <span class="math">\([0.0, 1.0]\)</span>. We use
the <a class="reference external" href="http://pytorch.org/docs/0.2.0/_modules/torchvision/datasets/mnist.html">MNIST data
loader</a>
from the torchvision library. The testing set consists of <span class="math">\(10000\)</span>
examples. The default training set consists of <span class="math">\(60000\)</span> examples.
We use the first <span class="math">\(50000\)</span> examples for training (divided into
supervised and un-supervised parts) and the remaining <span class="math">\(10000\)</span>
images for validation. For our experiments, we use <span class="math">\(4\)</span>
configurations of supervision in the training set, i.e.&nbsp;we consider
<span class="math">\(3000\)</span>, <span class="math">\(1000\)</span>, <span class="math">\(600\)</span> and <span class="math">\(100\)</span> supervised
examples selected randomly (while ensuring that each class is balanced).</p>
</div>
<div class="section" id="The-Objective-Function">
<h3>The Objective Function<a class="headerlink" href="#The-Objective-Function" title="Permalink to this headline">¶</a></h3>
<p>The objective function for this model has the two terms (c.f. Eqn. 8 in
reference [1]):</p>
<div class="math">
\[\mathcal{J} = \!\!\sum_{({\bf x,y}) \in \mathcal{D}_{supervised} } \!\!\!\!\!\!\!\!\mathcal{L}\big({\bf x,y}\big) +\!\!\! \sum_{{\bf x} \in \mathcal{D}_{unsupervised}} \!\!\!\!\!\!\!\mathcal{U}\left({\bf x}\right)\]</div>
<p>To implement this in Pyro, we setup a single instance of the <code class="docutils literal"><span class="pre">SVI</span></code>
class. The two different terms in the objective functions will emerge
automatically depending on whether we pass the <code class="docutils literal"><span class="pre">step</span></code> method labeled
or unlabeled data. We will alternate taking steps with labeled and
unlabeled mini-batches, with the number of steps taken for each type of
mini-batch depending on the total fraction of data that is labeled. For
example, if we have 1,000 labeled images and 49,000 unlabeled ones, then
we’ll take 49 steps with unlabeled mini-batches for each labeled
mini-batch. (Note that there are different ways we could do this, but
for simplicity we only consider this variant.) The code for this setup
is given below:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [3]:
</pre></div>
</div>
<div class="input_area highlight-ipython2"><div class="highlight"><pre>
<span></span>from pyro.infer import SVI
from pyro.optim import Adam

# setup the optimizer
adam_params = {&quot;lr&quot;: 0.0003}
optimizer = Adam(adam_params)

# setup the inference algorithm
svi = SVI(model, guide, optimizer, loss=&quot;ELBO&quot;)
</pre></div>
</div>
</div>
<p>When we run this inference in Pyro, the performance seen during test
time is degraded by the noise inherent in the sampling of the
categorical variables (see Figure 2 and Table 1 at the end of this
tutorial). To deal with this we’re going to need a better ELBO gradient
estimator.</p>
<center><figure>
    <table>
        <tr>
            <td style="width: 450px">
                <img src="_static/img/exp_1_losses_24_3000.png?2"  style="width: 450px;">
            </td>
            <td style="width: 450px">
                <img src="_static/img/exp_1_acc_24_3000.png?2" style="width: 450px;">
            </td>
        </tr>
    </table>
    <figcaption>
        <font size="+1"><b>Figure 2:</b> Variant 1</font> <b>(Left)</b> Training losses for the case with 3000 supervised examples.
        <b>(Right)</b> Test and validation accuracies.
    </figcaption>
</figure></center></div>
</div>
<div class="section" id="Interlude:-Summing-Out-Discrete-Latents">
<h2>Interlude: Summing Out Discrete Latents<a class="headerlink" href="#Interlude:-Summing-Out-Discrete-Latents" title="Permalink to this headline">¶</a></h2>
<p>As highlighted in the introduction, when the discrete latent labels
<span class="math">\({\bf y}\)</span> are not observed, the ELBO gradient estimates rely on
sampling from <span class="math">\(q_\phi({\bf y}|{\bf x})\)</span>. These gradient estimates
can be very high-variance, especially early in the learning process when
the guessed labels are often incorrect. A common approach to reduce
variance in this case is to sum out discrete latent variables, replacing
the Monte Carlo expectation</p>
<div class="math">
\[\mathbb E_{{\bf y}\sim q_\phi(\cdot|{\bf x})}\nabla\operatorname{ELBO}\]</div>
<p>with an explicit sum</p>
<div class="math">
\[\sum_{\bf y} q_\phi({\bf y}|{\bf x})\nabla\operatorname{ELBO}\]</div>
<p>This sum is usually implemented by hand, as in [1], but Pyro can
automate this in many cases. To automatically sum out all discrete
latent variables (here only <span class="math">\({\bf y}\)</span>), we simply pass the
<code class="docutils literal"><span class="pre">enum_discrete=True</span></code> argument to <code class="docutils literal"><span class="pre">SVI()</span></code>:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">svi</span> <span class="o">=</span> <span class="n">SVI</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">guide</span><span class="p">,</span> <span class="n">optim</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s2">&quot;ELBO&quot;</span><span class="p">,</span> <span class="n">enum_discrete</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</pre></div>
</div>
<p>In this mode of operation, each <code class="docutils literal"><span class="pre">svi.step(...)</span></code> computes a gradient
term for each of the ten latent states of <span class="math">\(y\)</span>. Although each step
is thus <span class="math">\(10\times\)</span> more expensive, we’ll see that the
lower-variance gradient estimate outweighs the additional cost.</p>
<p>Going beyond the particular model in this tutorial, Pyro supports
summing over arbitrarily many discrete latent variables. Beware that the
cost of summing is exponential in the number of discrete variables, but
is cheap(er) if multiple independent discrete variables are packed into
a single tensor (as in this tutorial, where the discrete labels for the
entire mini-batch are packed into the single tensor <span class="math">\({\bf y}\)</span>). To
use this parallel form of <code class="docutils literal"><span class="pre">enum_discrete</span></code>, we must inform Pyro that
the items in a minibatch are indeed independent by wrapping our
vectorized code in a <code class="docutils literal"><span class="pre">with</span> <span class="pre">iarange(&quot;name&quot;)</span></code> block.</p>
</div>
<div class="section" id="Second-Variant:-Standard-Objective-Function,-Better-Estimator">
<h2>Second Variant: Standard Objective Function, Better Estimator<a class="headerlink" href="#Second-Variant:-Standard-Objective-Function,-Better-Estimator" title="Permalink to this headline">¶</a></h2>
<p>Now that we have the technology to sum out discrete latents, we can see
if doing so helps our performance. First, as we can see from Figure 3,
the test and validation accuracies now evolve much more smoothly over
the course of training. More importantly, this single modification
improved test accuracy from around <code class="docutils literal"><span class="pre">20%</span></code> to about <code class="docutils literal"><span class="pre">90%</span></code> for the case
of <span class="math">\(3000\)</span> labeled examples. See Table 1 for the full results. This
is great, but can we do better?</p>
<center><figure>
    <table>
        <tr>
            <td>
                <img src="_static/img/exp_2_losses_56_3000.png?2"  style="width: 450px;">
            </td>
            <td>
                <img src="_static/img/exp_2_acc_56_3000.png?2" style="width: 450px;">
            </td>
        </tr>
    </table>
    <figcaption>
        <font size="+1"><b>Figure 3:</b> Variant 2</font> <b>(Left)</b> Training losses for the case with 3000 supervised examples.
        <b>(Right)</b> Test and validation accuracies.
    </figcaption>
</figure></center></div>
<div class="section" id="Third-Variant:-Adding-a-Term-to-the-Objective">
<h2>Third Variant: Adding a Term to the Objective<a class="headerlink" href="#Third-Variant:-Adding-a-Term-to-the-Objective" title="Permalink to this headline">¶</a></h2>
<p>For the two variants we’ve explored so far, the classifier
<span class="math">\(q_{\phi}({\bf y}~|~ {\bf x})\)</span> doesn’t learn directly from labeled
data. As we discussed in the introduction, this seems like a potential
problem. One approach to addressing this problem is to add an extra term
to the objective so that the classifier learns directly from labeled
data. Note that this is exactly the approach adopted in reference [1]
(see their Eqn. 9). The modified objective function is given by:</p>
<div class="math">
\[\begin{split}\begin{align}
    \mathcal{J}^{\alpha} &amp;= \mathcal{J} + \alpha \mathop{\mathbb{E}}_{\tilde{p_l}({\bf x,y})} \big[-\log\big(q_{\phi}({\bf y}~|~ {\bf x})\big)\big] \\
    &amp;= \mathcal{J} + \alpha' \sum_{({\bf x,y}) \in \mathcal{D}_{supervised}}  \big[-\log\big(q_{\phi}({\bf y}~|~ {\bf x})\big)\big]
\end{align}\end{split}\]</div>
<p>where <span class="math">\(\tilde{p_l}({\bf x,y})\)</span> is the empirical distribution over
the labeled (or supervised) data and
<span class="math">\(\alpha' \equiv \frac{\alpha}{|\mathcal{D}_{supervised}|}\)</span>. Note
that we’ve introduced an arbitrary hyperparameter <span class="math">\(\alpha\)</span> that
modulates the importance of the new term.</p>
<p>To learn using this modified objective in Pyro we do the following:</p>
<ul class="simple">
<li>We use a new model and guide pair (see the code snippet below) that
corresponds to scoring the observed label <span class="math">\({\bf y}\)</span> for a given
image <span class="math">\({\bf x}\)</span> against the predictive distribution
<span class="math">\(q_{\phi}({\bf y}~|~ {\bf x})\)</span></li>
<li>We specify the scaling factor <span class="math">\(\alpha'\)</span>
(<code class="docutils literal"><span class="pre">aux_loss_multiplier</span></code> in the code) in the <code class="docutils literal"><span class="pre">pyro.observe</span></code> call by
making use of the <code class="docutils literal"><span class="pre">log_pdf_mask</span></code> argument. Note that
<code class="docutils literal"><span class="pre">log_pdf_mask</span></code> was used to similar effect in the <a class="reference external" href="http://pyro.ai/examples/dmm.html">Deep Markov
Model</a> to implement KL
annealing.</li>
<li>We create a new <code class="docutils literal"><span class="pre">SVI</span></code> object and use it to take gradient steps on
the new objective term</li>
</ul>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [4]:
</pre></div>
</div>
<div class="input_area highlight-ipython2"><div class="highlight"><pre>
<span></span>def model_classify(xs, ys):
    # this yields the extra term in the objective function
    alpha = encoder_y.forward(xs)
    pyro.observe(&quot;y_aux&quot;, dist.categorical, ys, alpha,
                 log_pdf_mask=aux_loss_multiplier)

def guide_classify(xs, ys):
    # the guide is trivial, since there are no
    # latent random variables
    pass

svi_aux = SVI(model_classify, guide_classify, optimizer, loss=&quot;ELBO&quot;)
</pre></div>
</div>
</div>
<p>When we run inference in Pyro with the additional term in the objective,
we outperform both previous inference setups. For example, the test
accuracy for the case with <span class="math">\(3000\)</span> labeled examples improves from
<code class="docutils literal"><span class="pre">90%</span></code> to <code class="docutils literal"><span class="pre">96%</span></code> (see Figure 4 below and Table 1 in the next section).
Note that we used validation accuracy to select the hyperparameter
<span class="math">\(\alpha'\)</span>.</p>
<center><figure>
    <table>
        <tr>
            <td>
                <img src="_static/img/exp_3_losses_112_3000.png?2"  style="width: 450px;">
            </td>
            <td>
                <img src="_static/img/exp_3_acc_112_3000.png?2" style="width: 450px;">
            </td>
        </tr>
    </table>
    <figcaption>
        <font size="+1"><b>Figure 4:</b> Variant 3</font> <b>(Left)</b> Training losses for the case with 3000 supervised examples.
        <b>(Right)</b> Test and validation accuracies.
    </figcaption>
</figure></center></div>
<div class="section" id="Results">
<h2>Results<a class="headerlink" href="#Results" title="Permalink to this headline">¶</a></h2>
<table border="1" class="docutils">
<colgroup>
<col width="20%" />
<col width="18%" />
<col width="18%" />
<col width="18%" />
<col width="25%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Supervised
data</th>
<th class="head">First
variant</th>
<th class="head">Second
variant</th>
<th class="head">Third
variant</th>
<th class="head">Baseline
classifier</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>100</td>
<td>0.2007(0.0
353)</td>
<td>0.2254(0.0
346)</td>
<td>0.9319(0.0
060)</td>
<td>0.7712(0.0159)</td>
</tr>
<tr class="row-odd"><td>600</td>
<td>0.1791(0.0
244)</td>
<td>0.6939(0.0
345)</td>
<td>0.9437(0.0
070)</td>
<td>0.8716(0.0064)</td>
</tr>
<tr class="row-even"><td>1000</td>
<td>0.2006(0.0
295)</td>
<td>0.7562(0.0
235)</td>
<td>0.9487(0.0
038)</td>
<td>0.8863(0.0025)</td>
</tr>
<tr class="row-odd"><td>3000</td>
<td>0.1982(0.0
522)</td>
<td>0.8932(0.0
159)</td>
<td>0.9582(0.0
012)</td>
<td>0.9108(0.0015)</td>
</tr>
</tbody>
</table>
<center><p>Table 1: Result accuracies (with 95% confidence bounds) for different
inference methods</p>
</center><p>Table 1 collects our results from the three variants explored in the
tutorial. For comparison, we also show results from a simple classifier
baseline, which only makes use of the supervised data (and no latent
random variables). Reported are mean accuracies (with 95% confidence
bounds in parentheses) across five random selections of supervised data.</p>
<p>We first note that the results for the third variant—where we summed out
the discrete latent random variable <span class="math">\(\bf y\)</span> and made use of the
additional term in the objective function—reproduce the results reported
in reference [1]. This is encouraging, since it means that the
abstractions in Pyro proved flexible enough to accomodate the required
modeling and inference setup. Significantly, this flexibility was
evidently necessary to outperform the baseline. It’s also worth
emphasizing that the gap between the baseline and third variant of our
generative model setup increases as the number of labeled datapoints
decreases (maxing out at about 15% for the case with only 100 labeled
datapoints). This is a tantalizing result because it’s precisely in the
regime where we have few labeled data points that semi-supervised
learning is particularly attractive.</p>
<div class="section" id="Latent-Space-Visualization">
<h3>Latent Space Visualization<a class="headerlink" href="#Latent-Space-Visualization" title="Permalink to this headline">¶</a></h3>
<center><figure>
    <table>
        <tr>
            <td>
                <img src="_static/img/third_embedding.png?3" style="width: 450px;">
            </td>
        </tr>
    </table> <center>
    <figcaption>
        <font size="+1"><b>Figure 5:</b> Latent space embedding for variant 3 with 3000 supervised examples</font>
    </figcaption> </center>
</figure></center><p>We use T-SNE to reduce the dimensionality of the latent <span class="math">\(\bf z\)</span>
from <span class="math">\(50\)</span> to <span class="math">\(2\)</span> and visualize the 10 digit classes in
Figure 5. Note that the structure of the embedding is quite different
than that in the <a class="reference external" href="http://pyro.ai/examples/vae.html">VAE</a> case, where
the digits are clearly separated from one another in the embedding. This
make sense, since for the semi-supervised case the latent <span class="math">\(\bf z\)</span>
is free to use its representational capacity to model, e.g., handwriting
style, since the variation between digits is provided by the (partially
observed) labels.</p>
</div>
<div class="section" id="Conditional-image-generation">
<h3>Conditional image generation<a class="headerlink" href="#Conditional-image-generation" title="Permalink to this headline">¶</a></h3>
<center><figure>
    <table>
        <tr>
            <td>
                <img src="_static/img/conditional_samples/0.jpg"  style="width: 200px;">
            </td>
            <td>
                <img src="_static/img/conditional_samples/1.jpg" style="width: 200px;">
            </td>
            <td>
                <img src="_static/img/conditional_samples/2.jpg"  style="width: 200px;">
            </td>
            <td>
                <img src="_static/img/conditional_samples/3.jpg" style="width: 200px;">
            </td>
            <td>
                <img src="_static/img/conditional_samples/4.jpg"  style="width: 200px;">
            </td>
        </tr>
        <tr>
            <td>
                <img src="_static/img/conditional_samples/5.jpg"  style="width: 200px;">
            </td>
            <td>
                <img src="_static/img/conditional_samples/6.jpg" style="width: 200px;">
            </td>
            <td>
                <img src="_static/img/conditional_samples/7.jpg"  style="width: 200px;">
            </td>
            <td>
                <img src="_static/img/conditional_samples/8.jpg" style="width: 200px;">
            </td>
            <td>
                <img src="_static/img/conditional_samples/9.jpg"  style="width: 200px;">
            </td>
        </tr>
    </table> <center>
    <figcaption>
        <font size="+1"><b>Figure 6:</b> Conditional samples obtained by fixing the class label and varying <b>z</b> (for variant 3 with 3000 supervised examples)</font>
    </figcaption> </center>
</figure></center><p>We sampled <span class="math">\(100\)</span> images for each class label (<span class="math">\(0\)</span> to
<span class="math">\(9\)</span>) by sampling different values of the latent variable
<span class="math">\({\bf z}\)</span>. The diversity of handwriting styles exhibited by each
digit is consistent with what we saw in the T-SNE visualization,
suggesting that the representation learned by <span class="math">\(\bf z\)</span> is
disentangled from the class labels.</p>
</div>
</div>
<div class="section" id="Final-thoughts">
<h2>Final thoughts<a class="headerlink" href="#Final-thoughts" title="Permalink to this headline">¶</a></h2>
<p>We’ve seen that generative models offer a natural approach to
semi-supervised machine learning. One of the most attractive features of
generative models is that we can explore a large variety of models in a
single unified setting. In this tutorial we’ve only been able to explore
a small fraction of the possible model and inference setups that are
possible. There is no reason to expect that one variant is best;
depending on the dataset and application, there will be reason to prefer
one over another. And there a lot of variants (see Figure 7)!</p>
<center><figure><img src="_static/img/ss_vae_zoo.png" style="width: 300px;"><figcaption> <center><font size="+1"><b>Figure 7</b>: A zoo of semi-supervised generative models </font> </center></figcaption></figure></center><p>Some of these variants clearly make more sense than others, but a priori
it’s difficult to know which ones are worth trying out. This is
especially true once we open the door to more complicated setups, like
the two models at the bottom of the figure, which include an always
latent random variable <span class="math">\(\tilde{\bf y}\)</span> in addition to the
partially observed label <span class="math">\({\bf y}\)</span>. (Incidentally, this class of
models—see reference [2] for similar variants—offers another potential
solution to the ‘no training’ problem that we identified above.)</p>
<p>The reader probably doesn’t need any convincing that a systematic
exploration of even a fraction of these options would be incredibly
time-consuming and error-prone if each model and each inference
procedure were coded up by scratch. It’s only with the modularity and
abstraction made possible by a probabilistic programming system that we
can hope to explore the landscape of generative models with any kind of
nimbleness—and reap any awaiting rewards.</p>
<p>See the full code on
<a class="reference external" href="https://github.com/uber/pyro/blob/dev/examples/ss_vae_M2.py">Github</a>.</p>
</div>
<div class="section" id="References">
<h2>References<a class="headerlink" href="#References" title="Permalink to this headline">¶</a></h2>
<p>[1] <code class="docutils literal"><span class="pre">Semi-supervised</span> <span class="pre">Learning</span> <span class="pre">with</span> <span class="pre">Deep</span> <span class="pre">Generative</span> <span class="pre">Models</span></code>,
Diederik P. Kingma, Danilo J. Rezende, Shakir Mohamed, Max Welling</p>
<p>[2]
<code class="docutils literal"><span class="pre">Learning</span> <span class="pre">Disentangled</span> <span class="pre">Representations</span> <span class="pre">with</span> <span class="pre">Semi-Supervised</span> <span class="pre">Deep</span> <span class="pre">Generative</span> <span class="pre">Models</span></code>,
&nbsp;&nbsp;&nbsp;&nbsp; N. Siddharth, Brooks Paige, Jan-Willem Van de Meent, Alban
Desmaison, Frank Wood, &nbsp;&nbsp;&nbsp;&nbsp; Noah D. Goodman, Pushmeet Kohli, Philip H.S.
Torr</p>
</div>
</div>


           </div>
           <div class="articleComments">
            
           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
      
        <a href="air.html" class="btn btn-neutral" title="Attend Infer Repeat" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2017, Xiongyp.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'./',
            VERSION:'0.1.0',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="_static/jquery.js"></script>
      <script type="text/javascript" src="_static/underscore.js"></script>
      <script type="text/javascript" src="_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>