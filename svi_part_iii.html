

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>SVI Part III: ELBO Gradient Estimators &mdash; Pyro实例与教程 0.1.0 文档</title>
  

  
  
  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  

  

  
        <link rel="index" title="索引"
              href="genindex.html"/>
        <link rel="search" title="搜索" href="search.html"/>
    <link rel="top" title="Pyro实例与教程 0.1.0 文档" href="index.html"/>
        <link rel="next" title="Variational Autoencoders" href="vae.html"/>
        <link rel="prev" title="SVI Part II: Conditional Independence, Subsampling, and Amortization" href="svi_part_ii.html"/> 

  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="index.html" class="icon icon-home"> Pyro实例与教程
          

          
          </a>

          
            
            
              <div class="version">
                0.1.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="intro_part_i.html">Pyro里的模型：从原分布到随机函数</a></li>
<li class="toctree-l1"><a class="reference internal" href="intro_part_ii.html">Inference in Pyro: From Stochastic Functions to Marginal Distributions</a></li>
<li class="toctree-l1"><a class="reference internal" href="svi_part_i.html">SVI Part I: An Introduction to Stochastic Variational Inference in Pyro</a></li>
<li class="toctree-l1"><a class="reference internal" href="svi_part_ii.html">SVI Part II: Conditional Independence, Subsampling, and Amortization</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">SVI Part III: ELBO Gradient Estimators</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#Setup">Setup</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Easy-Case:-Reparameterizable-Random-Variables">Easy Case: Reparameterizable Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Tricky-Case:-Non-reparameterizable-Random-Variables">Tricky Case: Non-reparameterizable Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Variance-or-Why-I-Wish-I-Was-Doing-MLE-Deep-Learning">Variance or Why I Wish I Was Doing MLE Deep Learning</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Reducing-Variance-via-Dependency-Structure">Reducing Variance via Dependency Structure</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Aside:-Dependency-tracking-in-Pyro">Aside: Dependency tracking in Pyro</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Reducing-Variance-with-Data-Dependent-Baselines">Reducing Variance with Data-Dependent Baselines</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#Baselines-in-Pyro">Baselines in Pyro</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Neural-Baselines">Neural Baselines</a></li>
<li class="toctree-l4"><a class="reference internal" href="#A-complete-example-with-baselines">A complete example with baselines</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#References">References</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="vae.html">Variational Autoencoders</a></li>
<li class="toctree-l1"><a class="reference internal" href="bayesian_regression.html">Bayesian Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="dmm.html">Deep Markov Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="air.html">Attend Infer Repeat</a></li>
<li class="toctree-l1"><a class="reference internal" href="ss-vae.html">The Semi-Supervised VAE</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Pyro实例与教程</a>
        
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>SVI Part III: ELBO Gradient Estimators</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/svi_part_iii.ipynb.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput,
div.nbinput div.prompt,
div.nbinput div.input_area,
div.nbinput div[class*=highlight],
div.nbinput div[class*=highlight] pre,
div.nboutput,
div.nbinput div.prompt,
div.nbinput div.output_area,
div.nboutput div[class*=highlight],
div.nboutput div[class*=highlight] pre {
    background: none;
    border: none;
    padding: 0 0;
    margin: 0;
    box-shadow: none;
}

/* avoid gaps between output lines */
div.nboutput div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput,
div.nboutput {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput,
    div.nboutput {
        flex-direction: column;
    }
}

/* input container */
div.nbinput {
    padding-top: 5px;
}

/* last container */
div.nblast {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput div.prompt pre {
    color: #303F9F;
}

/* output prompt */
div.nboutput div.prompt pre {
    color: #D84315;
}

/* all prompts */
div.nbinput div.prompt,
div.nboutput div.prompt {
    min-width: 8ex;
    padding-top: 0.4em;
    padding-right: 0.4em;
    text-align: right;
    flex: 0;
}
@media (max-width: 540px) {
    div.nbinput div.prompt,
    div.nboutput div.prompt {
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput div.prompt.empty {
        padding: 0;
    }
}

/* disable scrollbars on prompts */
div.nbinput div.prompt pre,
div.nboutput div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput div.input_area,
div.nboutput div.output_area {
    padding: 0.4em;
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput div.input_area,
    div.nboutput div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput div.input_area {
    border: 1px solid #cfcfcf;
    border-radius: 2px;
    background: #f7f7f7;
}

/* override MathJax center alignment in output cells */
div.nboutput div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.pngmath center alignment in output cells */
div.nboutput div.math p {
    text-align: left;
}

/* standard error */
div.nboutput div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast,
.nboutput.nblast {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast + .nbinput {
    margin-top: -19px;
}

/* nice headers on first paragraph of info/warning boxes */
.admonition .first {
    margin: -12px;
    padding: 6px 12px;
    margin-bottom: 12px;
    color: #fff;
    line-height: 1;
    display: block;
}
.admonition.warning .first {
    background: #f0b37e;
}
.admonition.note .first {
    background: #6ab0de;
}
.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}
</style>
<div class="section" id="SVI-Part-III:-ELBO-Gradient-Estimators">
<h1>SVI Part III: ELBO Gradient Estimators<a class="headerlink" href="#SVI-Part-III:-ELBO-Gradient-Estimators" title="永久链接至标题">¶</a></h1>
<div class="section" id="Setup">
<h2>Setup<a class="headerlink" href="#Setup" title="永久链接至标题">¶</a></h2>
<p>We’ve defined a Pyro model with observations <span class="math">\({\bf x}\)</span> and latents
<span class="math">\({\bf z}\)</span> of the form
<span class="math">\(p_{\theta}({\bf x}, {\bf z}) = p_{\theta}({\bf x}|{\bf z}) p_{\theta}({\bf z})\)</span>.
We’ve also defined a Pyro guide (i.e.&nbsp;a variational distribution) of the
form <span class="math">\(q_{\phi}({\bf z})\)</span>. Here <span class="math">\({\theta}\)</span> and <span class="math">\(\phi\)</span>
are variational parameters for the model and guide, respectively. (In
particular these are <em>not</em> random variables that call for a Bayesian
treatment).</p>
<p>We’d like to maximize the log evidence <span class="math">\(\log p_{\theta}({\bf x})\)</span>
by maximizing the ELBO (the evidence lower bound) given by</p>
<div class="math">
\[{\rm ELBO} \equiv \mathbb{E}_{q_{\phi}({\bf z})} \left [
\log p_{\theta}({\bf x}, {\bf z}) - \log q_{\phi}({\bf z})
\right]\]</div>
<p>To do this we’re going to take (stochastic) gradient steps on the ELBO
in the parameter space <span class="math">\(\{ \theta, \phi \}\)</span> (see references [1,2]
for early work on this approach). So we need to be able to compute
unbiased estimates of</p>
<div class="math">
\[\nabla_{\theta,\phi} {\rm ELBO} = \nabla_{\theta,\phi}\mathbb{E}_{q_{\phi}({\bf z})} \left [
\log p_{\theta}({\bf x}, {\bf z}) - \log q_{\phi}({\bf z})
\right]\]</div>
<p>How do we do this for general stochastic functions <code class="docutils literal"><span class="pre">model()</span></code> and
<code class="docutils literal"><span class="pre">guide()</span></code>? To simplify notation let’s generalize our discussion a bit
and ask how we can compute gradients of expectations of an arbitrary
cost function <span class="math">\(f({\bf z})\)</span>. Let’s also drop any distinction
between <span class="math">\(\theta\)</span> and <span class="math">\(\phi\)</span>. So we want to compute</p>
<div class="math">
\[\nabla_{\phi}\mathbb{E}_{q_{\phi}({\bf z})} \left [
f_{\phi}({\bf z}) \right]\]</div>
<p>Let’s start with the easiest case.</p>
</div>
<div class="section" id="Easy-Case:-Reparameterizable-Random-Variables">
<h2>Easy Case: Reparameterizable Random Variables<a class="headerlink" href="#Easy-Case:-Reparameterizable-Random-Variables" title="永久链接至标题">¶</a></h2>
<p>Suppose that we can reparameterize things such that</p>
<div class="math">
\[\mathbb{E}_{q_{\phi}({\bf z})} \left [f_{\phi}({\bf z}) \right]
=\mathbb{E}_{q({\bf \epsilon})} \left [f_{\phi}(g_{\phi}({\bf \epsilon})) \right]\]</div>
<p>Crucially we’ve moved all the <span class="math">\(\phi\)</span> dependence inside of the
exectation; <span class="math">\(q({\bf \epsilon})\)</span> is a fixed distribution with no
dependence on <span class="math">\(\phi\)</span>. This kind of reparameterization can be done
for many distributions (e.g.&nbsp;the normal distribution); see reference [3]
for a discussion. In this case we can pass the gradient straight through
the expectation to get</p>
<div class="math">
\[\nabla_{\phi}\mathbb{E}_{q({\bf \epsilon})} \left [f_{\phi}(g_{\phi}({\bf \epsilon})) \right]=
\mathbb{E}_{q({\bf \epsilon})} \left [\nabla_{\phi}f_{\phi}(g_{\phi}({\bf \epsilon})) \right]\]</div>
<p>Assuming <span class="math">\(f(\cdot)\)</span> and <span class="math">\(g(\cdot)\)</span> are sufficiently smooth,
we can now get unbiased estimates of the gradient of interest by taking
a Monte Carlo estimate of this expectation.</p>
</div>
<div class="section" id="Tricky-Case:-Non-reparameterizable-Random-Variables">
<h2>Tricky Case: Non-reparameterizable Random Variables<a class="headerlink" href="#Tricky-Case:-Non-reparameterizable-Random-Variables" title="永久链接至标题">¶</a></h2>
<p>What if we can’t do the above reparameterization? Unfortunately this is
the case for many distributions of interest, for example all discrete
distributions. In this case our estimator takes a bit more complicated
form.</p>
<p>We begin by expanding the gradient of interest as</p>
<div class="math">
\[\nabla_{\phi}\mathbb{E}_{q_{\phi}({\bf z})} \left [
f_{\phi}({\bf z}) \right]=
\nabla_{\phi} \int d{\bf z} \; q_{\phi}({\bf z}) f_{\phi}({\bf z})\]</div>
<p>and use the chain rule to write this as</p>
<div class="math">
\[\int d{\bf z} \; \left \{ (\nabla_{\phi}  q_{\phi}({\bf z})) f_{\phi}({\bf z}) + q_{\phi}({\bf z})(\nabla_{\phi} f_{\phi}({\bf z}))\right \}\]</div>
<p>At this point we run into a problem. We know how to generate samples
from <span class="math">\(q(\cdot)\)</span>—we just run the guide forward—but
<span class="math">\(\nabla_{\phi} q_{\phi}({\bf z})\)</span> isn’t even a valid probability
density. So we need to massage this formula so that it’s in the form of
an expectation w.r.t. <span class="math">\(q(\cdot)\)</span>. This is easily done using the
identity</p>
<div class="math">
\[ \nabla_{\phi}  q_{\phi}({\bf z}) =
q_{\phi}({\bf z})\nabla_{\phi} \log q_{\phi}({\bf z})\]</div>
<p>which allows us to rewrite the gradient of interest as</p>
<div class="math">
\[\mathbb{E}_{q_{\phi}({\bf z})} \left [
(\nabla_{\phi} \log q_{\phi}({\bf z})) f_{\phi}({\bf z}) + \nabla_{\phi} f_{\phi}({\bf z})\right]\]</div>
<p>This form of the gradient estimator—variously known as the REINFORCE
estimator or the score function estimator or the likelihood ratio
estimator—is amenable to simple Monte Carlo estimation.</p>
<p>Note that one way to package this result (which is covenient for
implementation) is to introduce a surrogate loss function</p>
<div class="math">
\[{\rm surrogate \;loss} \equiv
\log q_{\phi}({\bf z}) \overline{f_{\phi}({\bf z})} + f_{\phi}({\bf z})\]</div>
<p>Here the bar indicates that the term is held constant (i.e.&nbsp;it is not to
be differentiated w.r.t. <span class="math">\(\phi\)</span>). To get a (single-sample) Monte
Carlo gradient estimate, we sample the latent random variables, compute
the surrogate loss, and differentiate. The result is an unbiased
estimate of
<span class="math">\(\nabla_{\phi}\mathbb{E}_{q_{\phi}({\bf z})} \left [ f_{\phi}({\bf z}) \right]\)</span>.
In equations:</p>
<div class="math">
\[\nabla_{\phi} {\rm ELBO} = \mathbb{E}_{q_{\phi}({\bf z})} \left [
\nabla_{\phi} ({\rm surrogate \; loss}) \right]\]</div>
</div>
<div class="section" id="Variance-or-Why-I-Wish-I-Was-Doing-MLE-Deep-Learning">
<h2>Variance or Why I Wish I Was Doing MLE Deep Learning<a class="headerlink" href="#Variance-or-Why-I-Wish-I-Was-Doing-MLE-Deep-Learning" title="永久链接至标题">¶</a></h2>
<p>We now have a general recipe for an unbiased gradient estimator of
expectations of cost functions. Unfortunately, in the more general case
where our <span class="math">\(q(\cdot)\)</span> includes non-reparameterizable random
variables, this estimator tends to have high variance. Indeed in many
cases of interest the variance is so high that the estimator is
effectively unusable. So we need strategies to reduce variance (for a
discussion see reference [4]). We’re going to pursue two strategies. The
first strategy takes advantage of the particular structure of the cost
function <span class="math">\(f(\cdot)\)</span>. The second strategy effectively introduces a
way to reduce variance by using information from previous estimates of
<span class="math">\(\mathbb{E}_{q_{\phi}({\bf z})} [ f_{\phi}({\bf z})]\)</span>. As such it
is somewhat analogous to using momentum in stochastic gradient descent.</p>
<div class="section" id="Reducing-Variance-via-Dependency-Structure">
<h3>Reducing Variance via Dependency Structure<a class="headerlink" href="#Reducing-Variance-via-Dependency-Structure" title="永久链接至标题">¶</a></h3>
<p>In the above discussion we stuck to a general cost function
<span class="math">\(f_{\phi}({\bf z})\)</span>. We could continue in this vein (the approach
we’re about to discuss is applicable in the general case) but for
concreteness let’s zoom back in. In the case of stochastic variational
inference, we’re interested in a particular cost function of the form</p>
<div class="math">
\[\log p_{\theta}({\bf x} | {\rm Pa}_p ({\bf x})) +
\sum_i \log p_{\theta}({\bf z}_i | {\rm Pa}_p ({\bf z}_i))
- \sum_i \log q_{\phi}({\bf z}_i | {\rm Pa}_q ({\bf z}_i))\]</div>
<p>where we’ve broken the log ratio
<span class="math">\(\log p_{\theta}({\bf x}, {\bf z})/q_{\phi}({\bf z})\)</span> into an
observation log likelihood piece and a sum over the different latent
random variables <span class="math">\(\{{\bf z}_i \}\)</span>. We’ve also introduced the
notation <span class="math">\({\rm Pa}_p (\cdot)\)</span> and <span class="math">\({\rm Pa}_q (\cdot)\)</span> to
denote the parents of a given random variable in the model and in the
guide, respectively. (The reader might worry what the appropriate notion
of dependency would be in the case of general stochastic functions; here
we simply mean regular ol’ dependency within a single execution trace).
The point is that different terms in the cost function have different
dependencies on the random variables <span class="math">\(\{ {\bf z}_i \}\)</span> and this is
something we can leverage.</p>
<p>To make a long story short, for any non-reparameterizable latent random
variable <span class="math">\({\bf z}_i\)</span> the surrogate loss is going to have a term</p>
<div class="math">
\[\log q_{\phi}({\bf z}_i) \overline{f_{\phi}({\bf z})}\]</div>
<p>It turns out that we can remove some of the terms in
<span class="math">\(\overline{f_{\phi}({\bf z})}\)</span> and still get an unbiased gradient
estimator; furthermore, doing so will generally decrease the variance.
In particular (see reference [4] for details) we can remove any terms in
<span class="math">\(\overline{f_{\phi}({\bf z})}\)</span> that are not downstream of the
latent variable <span class="math">\({\bf z}_i\)</span> (downstream w.r.t. to the dependency
structure of the guide).</p>
<p>In Pyro, all of this logic is taken care of automatically by the <code class="docutils literal"><span class="pre">SVI</span></code>
class. In particular as long as we switch on <code class="docutils literal"><span class="pre">trace_graph=True</span></code>, Pyro
will keep track of the dependency structure within the execution traces
of the model and guide and construct a surrogate loss that has all the
unnecessary terms removed:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">svi</span> <span class="o">=</span> <span class="n">SVI</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">guide</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="s2">&quot;ELBO&quot;</span><span class="p">,</span> <span class="n">trace_graph</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</pre></div>
</div>
<p>Note that leveraging this dependency information takes extra
computations, so <code class="docutils literal"><span class="pre">trace_graph=True</span></code> should only be invoked in the case
where your model has non-reparameterizable random variables.</p>
</div>
<div class="section" id="Aside:-Dependency-tracking-in-Pyro">
<h3>Aside: Dependency tracking in Pyro<a class="headerlink" href="#Aside:-Dependency-tracking-in-Pyro" title="永久链接至标题">¶</a></h3>
<p>Finally, a word about dependency tracking. Tracking dependency within a
stochastic function that includes arbitrary Python code is a bit tricky.
The approach currently implemented in Pyro is analogous to the one used
in WebPPL (cf.&nbsp;reference [5]). Briefly, a conservative notion of
dependency is used that relies on sequential ordering. If random
variable <span class="math">\({\bf z}_2\)</span> follows <span class="math">\({\bf z}_1\)</span> in a given
stochastic function then <span class="math">\({\bf z}_2\)</span> <em>may be</em> dependent on
<span class="math">\({\bf z}_1\)</span> and therefore <em>is</em> assumed to be dependent. To
mitigate the overly coarse conclusions that can be drawn by this kind of
dependency tracking, Pyro includes constructs for declaring things as
independent, namely <code class="docutils literal"><span class="pre">irange</span></code> and <code class="docutils literal"><span class="pre">iarange</span></code> (<a class="reference external" href="svi_part_ii.html">see the previous
tutorial</a>). For use cases with
non-reparameterizable variables, it is therefore important for the user
to make use of these constructs (when applicable) to take full advantage
of the variance reduction provided by <code class="docutils literal"><span class="pre">SVI</span></code>. In some cases it may also
pay to consider reordering random variables within a stochastic function
(if possible). It’s also worth noting that we expect to add finer
notions of dependency tracking in a future version of Pyro.</p>
</div>
<div class="section" id="Reducing-Variance-with-Data-Dependent-Baselines">
<h3>Reducing Variance with Data-Dependent Baselines<a class="headerlink" href="#Reducing-Variance-with-Data-Dependent-Baselines" title="永久链接至标题">¶</a></h3>
<p>The second strategy for reducing variance in our ELBO gradient estimator
goes under the name of baselines (see e.g.&nbsp;reference [6]). It actually
makes use of the same bit of math that underlies the variance reduction
strategy discussed above, except now instead of removing terms we’re
going to add terms. Basically, instead of removing terms with zero
expectation that tend to <em>contribute</em> to the variance, we’re going to
add specially chosen terms with zero expectation that work to <em>reduce</em>
the variance. As such, this is a control variate strategy.</p>
<p>In more detail, the idea is to take advantage of the fact that for any
constant <span class="math">\(b\)</span>, the following identity holds</p>
<div class="math">
\[\mathbb{E}_{q_{\phi}({\bf z})} \left [\nabla_{\phi}
(\log q_{\phi}({\bf z}) \times b) \right]=0\]</div>
<p>This follows since <span class="math">\(q(\cdot)\)</span> is normalized:</p>
<div class="math">
\[\mathbb{E}_{q_{\phi}({\bf z})} \left [\nabla_{\phi}
\log q_{\phi}({\bf z}) \right]=
 \int \!d{\bf z} \; q_{\phi}({\bf z}) \nabla_{\phi}
\log q_{\phi}({\bf z})=
 \int \! d{\bf z} \; \nabla_{\phi} q_{\phi}({\bf z})=
\nabla_{\phi} \int \! d{\bf z} \;  q_{\phi}({\bf z})=\nabla_{\phi} 1 = 0\]</div>
<p>What this means is that we can replace any term</p>
<div class="math">
\[\log q_{\phi}({\bf z}_i) \overline{f_{\phi}({\bf z})}\]</div>
<p>in our surrogate loss with</p>
<div class="math">
\[\log q_{\phi}({\bf z}_i) \left(\overline{f_{\phi}({\bf z})}-b\right)\]</div>
<p>Doing so doesn’t affect the mean of our gradient estimator but it does
affect the variance. If we choose <span class="math">\(b\)</span> wisely, we can hope to
reduce the variance. In fact, <span class="math">\(b\)</span> need not be a constant: it can
depend on any of the random choices upstream (or sidestream) of
<span class="math">\({\bf z}_i\)</span>.</p>
<div class="section" id="Baselines-in-Pyro">
<h4>Baselines in Pyro<a class="headerlink" href="#Baselines-in-Pyro" title="永久链接至标题">¶</a></h4>
<p>There are several ways the user can instruct Pyro to use baselines in
the context of stochastic variational inference. Since baselines can be
attached to any non-reparameterizable random variable, the current
baseline interface is at the level of the <code class="docutils literal"><span class="pre">pyro.sample</span></code> statement. In
particular the baseline interface makes use of an argument <code class="docutils literal"><span class="pre">baseline</span></code>,
which is a dictionary that specifies baseline options. Note that it only
makes sense to specify baselines for sample statements within the guide
(and not in the model).</p>
<div class="section" id="Decaying-Average-Baseline">
<h5>Decaying Average Baseline<a class="headerlink" href="#Decaying-Average-Baseline" title="永久链接至标题">¶</a></h5>
<p>The simplest baseline is constructed from a running average of recent
samples of <span class="math">\(\overline{f_{\phi}({\bf z})}\)</span>. In Pyro this kind of
baseline can be invoked as follows</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">z</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;z&quot;</span><span class="p">,</span> <span class="n">dist</span><span class="o">.</span><span class="n">bernoulli</span><span class="p">,</span> <span class="o">...</span><span class="p">,</span>
                <span class="n">baseline</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;use_decaying_avg_baseline&#39;</span><span class="p">:</span> <span class="bp">True</span><span class="p">,</span>
                          <span class="s1">&#39;baseline_beta&#39;</span><span class="p">:</span> <span class="mf">0.95</span><span class="p">})</span>
</pre></div>
</div>
<p>The optional argument <code class="docutils literal"><span class="pre">baseline_beta</span></code> specifies the decay rate of the
decaying average (default value: <code class="docutils literal"><span class="pre">0.90</span></code>).</p>
</div>
</div>
<div class="section" id="Neural-Baselines">
<h4>Neural Baselines<a class="headerlink" href="#Neural-Baselines" title="永久链接至标题">¶</a></h4>
<p>In some cases a decaying average baseline works well. In others using a
baseline that depends on upstream randomness is crucial for getting good
variance reduction. A powerful approach for constructing such a baseline
is to use a neural network that can be adapted during the course of
learning. Pyro provides two ways to specify such a baseline (for an
extended example see the <a class="reference external" href="air.html">AIR tutorial</a>).</p>
<p>First the user needs to decide what inputs the baseline is going to
consume (e.g.&nbsp;the current datapoint under consideration or the
previously sampled random variable). Then the user needs to construct a
<code class="docutils literal"><span class="pre">nn.Module</span></code> that encapsulates the baseline computation. This might
look something like</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">BaselineNN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim_input</span><span class="p">,</span> <span class="n">dim_hidden</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">BaselineNN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dim_input</span><span class="p">,</span> <span class="n">dim_hidden</span><span class="p">)</span>
        <span class="c1"># ... finish initialization ...</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="c1"># ... do more computations ...</span>
        <span class="k">return</span> <span class="n">baseline</span>
</pre></div>
</div>
<p>Then, assuming the BaselineNN object <code class="docutils literal"><span class="pre">baseline_module</span></code> has been
initialized somewhere else, in the guide we’ll have something like</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">guide</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>  <span class="c1"># here x is the current mini-batch of data</span>
    <span class="n">pyro</span><span class="o">.</span><span class="n">module</span><span class="p">(</span><span class="s2">&quot;my_baseline&quot;</span><span class="p">,</span> <span class="n">baseline_module</span><span class="p">,</span> <span class="n">tags</span><span class="o">=</span><span class="s2">&quot;baseline&quot;</span><span class="p">)</span>
    <span class="c1"># ... other computations ...</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;z&quot;</span><span class="p">,</span> <span class="n">dist</span><span class="o">.</span><span class="n">bernoulli</span><span class="p">,</span> <span class="o">...</span><span class="p">,</span>
                    <span class="n">baseline</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;nn_baseline&#39;</span><span class="p">:</span> <span class="n">baseline_module</span><span class="p">,</span>
                              <span class="s1">&#39;nn_baseline_input&#39;</span><span class="p">:</span> <span class="n">x</span><span class="p">})</span>
</pre></div>
</div>
<p>Here the argument <code class="docutils literal"><span class="pre">nn_baseline</span></code> tells Pyro which <code class="docutils literal"><span class="pre">nn.Module</span></code> to use
to construct the baseline. On the backend the argument
<code class="docutils literal"><span class="pre">nn_baseline_input</span></code> is fed into the forward method of the module to
compute the baseline <span class="math">\(b\)</span>. Note that the baseline module needs to
be registered with Pyro with a <code class="docutils literal"><span class="pre">pyro.module</span></code> call so that Pyro is
aware of the trainable parameters within the module.</p>
<p>Under the hood Pyro constructs a loss of the form</p>
<div class="math">
\[{\rm baseline\; loss} \equiv\left(\overline{f_{\phi}({\bf z})} - b  \right)^2\]</div>
<p>which is used to adapt the parameters of the neural network. There’s no
theorem that suggests this is the optimal loss function to use in this
context (it’s not), but in practice it can work pretty well. Just as for
the decaying average baseline, the idea is that a baseline that can
track the mean <span class="math">\(\overline{f_{\phi}({\bf z})}\)</span> will help reduce the
variance. Under the hood <code class="docutils literal"><span class="pre">SVI</span></code> takes one step on the baseline loss in
conjunction with a step on the ELBO.</p>
<p>Note that the module <code class="docutils literal"><span class="pre">baseline_module</span></code> has been tagged with the string
<code class="docutils literal"><span class="pre">&quot;baseline&quot;</span></code> above; this has the effect of tagging all parameters
inside of <code class="docutils literal"><span class="pre">baseline_module</span></code> with the parameter tag <code class="docutils literal"><span class="pre">&quot;baseline&quot;</span></code>.
This gives the user a convenient handle for controlling how the baseline
parameters are optimized. For example, if the user wants the baseline
parameters to have a larger learning rate (usually a good idea) an
appropriate optimizer could be constructed as follows:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">per_param_args</span><span class="p">(</span><span class="n">module_name</span><span class="p">,</span> <span class="n">param_name</span><span class="p">,</span> <span class="n">tags</span><span class="p">):</span>
    <span class="k">if</span> <span class="s1">&#39;baseline&#39;</span> <span class="ow">in</span> <span class="n">tags</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="mf">0.010</span><span class="p">}</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="mf">0.001</span><span class="p">}</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">per_param_args</span><span class="p">)</span>
</pre></div>
</div>
<p>Note that in order for the overall procedure to be correct the baseline
parameters should only be optimized through the baseline loss. Similarly
the model and guide parameters should only be optimized through the
ELBO. To ensure that this is the case under the hood <code class="docutils literal"><span class="pre">SVI</span></code> detaches
the baseline <span class="math">\(b\)</span> that enters the ELBO from the autograd graph.
Also, since the inputs to the neural baseline may depend on the
parameters of the model and guide, the inputs are also detached from the
autograd graph before they are fed into the neural network.</p>
<p>Finally, there is an alternate way for the user to specify a neural
baseline. Simply use the argument <code class="docutils literal"><span class="pre">baseline_value</span></code>:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">b</span> <span class="o">=</span> <span class="c1"># do baseline computation</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;z&quot;</span><span class="p">,</span> <span class="n">dist</span><span class="o">.</span><span class="n">bernoulli</span><span class="p">,</span> <span class="o">...</span><span class="p">,</span>
                <span class="n">baseline</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;baseline_value&#39;</span><span class="p">:</span> <span class="n">b</span><span class="p">})</span>
</pre></div>
</div>
<p>This works as above, except in this case it’s the user’s responsibility
to make sure that any autograd tape connecting <span class="math">\(b\)</span> to the
parameters of the model and guide has been cut. Or to say the same thing
in language more familiar to PyTorch users, any inputs to <span class="math">\(b\)</span> that
depend on <span class="math">\(\theta\)</span> or <span class="math">\(\phi\)</span> need to be detached from the
autograd graph with <code class="docutils literal"><span class="pre">detach()</span></code> statements.</p>
</div>
<div class="section" id="A-complete-example-with-baselines">
<h4>A complete example with baselines<a class="headerlink" href="#A-complete-example-with-baselines" title="永久链接至标题">¶</a></h4>
<p>Recall that in the <a class="reference external" href="svi_part_i.html">first SVI tutorial</a> we
considered a bernoulli-beta model for coin flips. Because the beta
random variable is non-reparameterizable, the corresponding ELBO
gradients are quite noisy. In that context we dealt with this problem by
dialing up the number of gradient steps we took. This isn’t necessarily
a bad approach, but it can be an expensive one. Here we showcase how a
simple decaying average baseline can reduce the variance. While we’re at
it, we also use <code class="docutils literal"><span class="pre">iarange</span></code> to write our model in a fully vectorized
manner.</p>
<p>Instead of directly comparing gradient variances, we’re going to see how
many steps it takes for SVI to converge. Recall that for this particular
model (because of conjugacy) we can compute the exact posterior. So to
assess the utility of baselines in this context, we setup the following
simple experiment. We initialize the guide at a specified set of
variational parameters. We then do SVI until the variational parameters
have gotten to within a fixed tolerance of the parameters of the exact
posterior. We do this both with and without the decaying average
baseline. We then compare the number of gradient steps we needed in the
two cases. Here’s the complete code:</p>
<p>(<em>Since apart from the use of</em> <code class="docutils literal"><span class="pre">iarange</span></code> <em>and</em>
<code class="docutils literal"><span class="pre">use_decaying_avg_baseline</span></code>, <em>this code is very similar to the code in
parts I and II of the SVI tutorial, we’re not going to go through the
code line by line.</em>)</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [1]:
</pre></div>
</div>
<div class="input_area highlight-ipython2"><div class="highlight"><pre>
<span></span>from __future__ import print_function
import numpy as np
import torch
from torch.autograd import Variable
import pyro
import pyro.distributions as dist
import pyro.optim as optim
from pyro.infer import SVI
import sys


def param_abs_error(name, target):
    return torch.sum(torch.abs(target - pyro.param(name))).data.numpy()[0]


class BernoulliBetaExample(object):
    def __init__(self):
        # the two hyperparameters for the beta prior
        self.alpha0 = Variable(torch.Tensor([10.0]))
        self.beta0 = Variable(torch.Tensor([10.0]))
        # the dataset consists of six 1s and four 0s
        self.data = Variable(torch.zeros(10,1))
        self.data[0:6, 0].data = torch.ones(6)
        self.n_data = self.data.size(0)
        # compute the alpha parameter of the exact beta posterior
        self.alpha_n = self.alpha0 + self.data.sum()
        # compute the beta parameter of the exact beta posterior
        self.beta_n = self.beta0 - self.data.sum() + Variable(torch.Tensor([self.n_data]))
        # for convenience compute the logs
        self.log_alpha_n = torch.log(self.alpha_n)
        self.log_beta_n = torch.log(self.beta_n)

    def setup(self):
        # initialize values of the two variational parameters
        # set to be quite close to the true values
        # so that the experiment doesn&#39;t take too long
        self.log_alpha_q_0 = Variable(torch.Tensor([np.log(15.0)]), requires_grad=True)
        self.log_beta_q_0 = Variable(torch.Tensor([np.log(15.0)]), requires_grad=True)

    def model(self, use_decaying_avg_baseline):
        # sample `latent_fairness` from the beta prior
        f = pyro.sample(&quot;latent_fairness&quot;, dist.beta, self.alpha0, self.beta0)
        # use iarange to indicate that the observations are
        # conditionally independent given f and get vectorization
        with pyro.iarange(&quot;data_iarange&quot;):
            # observe all ten datapoints using the bernoulli likelihood
            pyro.observe(&quot;obs&quot;, dist.bernoulli, self.data, f)

    def guide(self, use_decaying_avg_baseline):
        # register the two variational parameters with pyro
        log_alpha_q = pyro.param(&quot;log_alpha_q&quot;, self.log_alpha_q_0)
        log_beta_q = pyro.param(&quot;log_beta_q&quot;, self.log_beta_q_0)
        alpha_q, beta_q = torch.exp(log_alpha_q), torch.exp(log_beta_q)
        # sample f from the beta variational distribution
        baseline_dict = {&#39;use_decaying_avg_baseline&#39;: use_decaying_avg_baseline,
                         &#39;baseline_beta&#39;: 0.90}
        # note that the baseline_dict specifies whether we&#39;re using
        # decaying average baselines or not
        pyro.sample(&quot;latent_fairness&quot;, dist.beta, alpha_q, beta_q,
                    baseline=baseline_dict)

    def do_inference(self, use_decaying_avg_baseline, tolerance=0.05):
        # clear the param store in case we&#39;re in a REPL
        pyro.clear_param_store()
        # initialize the variational parameters for this run
        self.setup()
        # setup the optimizer and the inference algorithm
        optimizer = optim.Adam({&quot;lr&quot;: .0008, &quot;betas&quot;: (0.93, 0.999)})
        svi = SVI(self.model, self.guide, optimizer, loss=&quot;ELBO&quot;, trace_graph=True)
        print(&quot;Doing inference with use_decaying_avg_baseline=%s&quot; % use_decaying_avg_baseline)

        # do up to 10000 steps of inference
        for k in range(10000):
            svi.step(use_decaying_avg_baseline)
            if k % 100 == 0:
                print(&#39;.&#39;, end=&#39;&#39;)
                sys.stdout.flush()

            # compute the distance to the parameters of the true posterior
            alpha_error = param_abs_error(&quot;log_alpha_q&quot;, self.log_alpha_n)
            beta_error = param_abs_error(&quot;log_beta_q&quot;, self.log_beta_n)

            # stop inference early if we&#39;re close to the true posterior
            if alpha_error &lt; tolerance and beta_error &lt; tolerance:
                break

        print(&quot;\nDid %d steps of inference.&quot; % k)
        print((&quot;Final absolute errors for the two variational parameters &quot; +
               &quot;(in log space) were %.4f &amp; %.4f&quot;) % (alpha_error, beta_error))

# do the experiment
bbe = BernoulliBetaExample()
bbe.do_inference(use_decaying_avg_baseline=True)
bbe.do_inference(use_decaying_avg_baseline=False)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">ImportError</span>                               Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-1-c0f5f669cf9b&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-intense-fg ansi-bold">      1</span> <span class="ansi-green-intense-fg ansi-bold">from</span> __future__ <span class="ansi-green-intense-fg ansi-bold">import</span> print_function
<span class="ansi-green-intense-fg ansi-bold">      2</span> <span class="ansi-green-intense-fg ansi-bold">import</span> numpy <span class="ansi-green-intense-fg ansi-bold">as</span> np
<span class="ansi-green-fg">----&gt; 3</span><span class="ansi-red-fg"> </span><span class="ansi-green-intense-fg ansi-bold">import</span> torch
<span class="ansi-green-intense-fg ansi-bold">      4</span> <span class="ansi-green-intense-fg ansi-bold">from</span> torch<span class="ansi-yellow-intense-fg ansi-bold">.</span>autograd <span class="ansi-green-intense-fg ansi-bold">import</span> Variable
<span class="ansi-green-intense-fg ansi-bold">      5</span> <span class="ansi-green-intense-fg ansi-bold">import</span> pyro

<span class="ansi-red-fg">ImportError</span>: No module named torch
</pre></div></div>
</div>
<p><strong>Sample output:</strong></p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">Doing</span> <span class="n">inference</span> <span class="k">with</span> <span class="n">use_decaying_avg_baseline</span><span class="o">=</span><span class="kc">True</span>
<span class="o">...........</span>
<span class="n">Did</span> <span class="mi">2070</span> <span class="n">steps</span> <span class="n">of</span> <span class="n">inference</span><span class="o">.</span>
<span class="n">Final</span> <span class="n">absolute</span> <span class="n">errors</span> <span class="k">for</span> <span class="n">the</span> <span class="n">two</span> <span class="n">variational</span> <span class="n">parameters</span> <span class="p">(</span><span class="ow">in</span> <span class="n">log</span> <span class="n">space</span><span class="p">)</span> <span class="n">were</span> <span class="mf">0.0500</span> <span class="o">&amp;</span> <span class="mf">0.0443</span>
<span class="n">Doing</span> <span class="n">inference</span> <span class="k">with</span> <span class="n">use_decaying_avg_baseline</span><span class="o">=</span><span class="kc">False</span>
<span class="o">.....................</span>
<span class="n">Did</span> <span class="mi">4159</span> <span class="n">steps</span> <span class="n">of</span> <span class="n">inference</span><span class="o">.</span>
<span class="n">Final</span> <span class="n">absolute</span> <span class="n">errors</span> <span class="k">for</span> <span class="n">the</span> <span class="n">two</span> <span class="n">variational</span> <span class="n">parameters</span> <span class="p">(</span><span class="ow">in</span> <span class="n">log</span> <span class="n">space</span><span class="p">)</span> <span class="n">were</span> <span class="mf">0.0500</span> <span class="o">&amp;</span> <span class="mf">0.0306</span>
</pre></div>
</div>
<p>For this particular run we can see that baselines roughly halved the
number of steps of SVI we needed to do. The results are stochastic and
will vary from run to run, but this is an encouraging result. For
certain model and guide pairs, baselines can provide an even bigger win.</p>
</div>
</div>
</div>
<div class="section" id="References">
<h2>References<a class="headerlink" href="#References" title="永久链接至标题">¶</a></h2>
<p>[1] <code class="docutils literal"><span class="pre">Automated</span> <span class="pre">Variational</span> <span class="pre">Inference</span> <span class="pre">in</span> <span class="pre">Probabilistic</span> <span class="pre">Programming</span></code>,
&nbsp;&nbsp;&nbsp;&nbsp; David Wingate, Theo Weber</p>
<p>[2] <code class="docutils literal"><span class="pre">Black</span> <span class="pre">Box</span> <span class="pre">Variational</span> <span class="pre">Inference</span></code>,&nbsp;&nbsp;&nbsp;&nbsp; Rajesh Ranganath, Sean
Gerrish, David M. Blei</p>
<p>[3] <code class="docutils literal"><span class="pre">Auto-Encoding</span> <span class="pre">Variational</span> <span class="pre">Bayes</span></code>,&nbsp;&nbsp;&nbsp;&nbsp; Diederik P Kingma, Max
Welling</p>
<p>[4] <code class="docutils literal"><span class="pre">Gradient</span> <span class="pre">Estimation</span> <span class="pre">Using</span> <span class="pre">Stochastic</span> <span class="pre">Computation</span> <span class="pre">Graphs</span></code>,
John Schulman, Nicolas Heess, Theophane Weber, Pieter Abbeel</p>
<p>[5] <code class="docutils literal"><span class="pre">Deep</span> <span class="pre">Amortized</span> <span class="pre">Inference</span> <span class="pre">for</span> <span class="pre">Probabilistic</span> <span class="pre">Programs</span></code> &nbsp;&nbsp;&nbsp;&nbsp; Daniel
Ritchie, Paul Horsfall, Noah D. Goodman</p>
<p>[6] <code class="docutils literal"><span class="pre">Neural</span> <span class="pre">Variational</span> <span class="pre">Inference</span> <span class="pre">and</span> <span class="pre">Learning</span> <span class="pre">in</span> <span class="pre">Belief</span> <span class="pre">Networks</span></code>
&nbsp;&nbsp;&nbsp;&nbsp; Andriy Mnih, Karol Gregor</p>
</div>
</div>


           </div>
           <div class="articleComments">
            
           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="vae.html" class="btn btn-neutral float-right" title="Variational Autoencoders" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="svi_part_ii.html" class="btn btn-neutral" title="SVI Part II: Conditional Independence, Subsampling, and Amortization" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2017, 小熊.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'./',
            VERSION:'0.1.0',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="_static/jquery.js"></script>
      <script type="text/javascript" src="_static/underscore.js"></script>
      <script type="text/javascript" src="_static/doctools.js"></script>
      <script type="text/javascript" src="_static/translations.js"></script>
      <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>